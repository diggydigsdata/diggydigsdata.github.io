[
  {
    "objectID": "posts/winner-takes-them-all/index.html",
    "href": "posts/winner-takes-them-all/index.html",
    "title": "The Winner Takes Them All (Project Map with Power BI Dashboard)",
    "section": "",
    "text": "Football credits the taker of a penalty, not the player who won it. That‚Äôs why we end up with nicknames like ‚ÄúPenaldo‚Äù. A BBC caption - ‚ÄúMisstiano Penaldo‚Äù - even went viral after CR7 missed against Slovenia in 2024.\nThis project asks a simple counterfactual:\nWhat would happen if penalties were allocated back to the players who won them? How would that change the way we look at player statlines across seasons, careers or during Balon d‚ÄôOr discussons?\nAnd why not just give them the full goals? Because this is a counterfactual allocation problem, we have to account for the possibility that they would miss. So my made-up metric is Expected Goals from Penalties Won (xGpw), which is currently fixed at 0.757 for every player, though I do plan to tweak this. Explanation of all that to follow.\nSo far, the workflow is:\nThis isn‚Äôt intended as a one-off analysis ‚Äî it‚Äôs a pipeline project. Long-term, I plan to transition this pipeline to a paid football API to ensure scalability and commercial compliance. The data I scraped is just for my experimentation with the above workflow. In future, I intend to make a Shiny dashboard that automatically refreshes data, and fully explorable by site visitors. I will periodically publish small vignettes based on my own exploration."
  },
  {
    "objectID": "posts/winner-takes-them-all/index.html#dashboard-prototype",
    "href": "posts/winner-takes-them-all/index.html#dashboard-prototype",
    "title": "The Winner Takes Them All (Project Map with Power BI Dashboard)",
    "section": "Dashboard (prototype)",
    "text": "Dashboard (prototype)\nHere is a small prototype I made in Power Bi.\n\nKnown limitations (current dashboard)\n\nThis can only be filtered to a single-season / single-competition grain as I have encountered issues with my DAX measures.\nCross-filter interactions can be annoying (table clicks affecting cards in ways I don‚Äôt want)"
  },
  {
    "objectID": "posts/strava-gap-metric/index.html",
    "href": "posts/strava-gap-metric/index.html",
    "title": "Grade Adjusted Pace (GAP)",
    "section": "",
    "text": "Disclaimer\n\n\n\nThis article is an independent technical-writing sample created solely for portfolio and demonstration purposes.\nIt is not affiliated with, endorsed by, or produced on behalf of Strava.\nAll explanations of Grade Adjusted Pace (GAP), its behaviour, and its underlying logic are my own interpretations based on publicly available Strava documentation, Strava Engineering blog posts, and the academic research cited in the bibliography below.\nAll datasets, adjustment factors, charts, and code shown here are synthetic examples created by me for illustration only. They should not be interpreted as precise reproductions of Strava‚Äôs proprietary data or algorithms.\nCertain stylistic elements‚Äîsuch as layout choices, callout boxes, metadata fields like ‚ÄúLast modified,‚Äù and the overall structure‚Äîintentionally emulate the conventions of corporate technical blogs and documentation. These are used purely to demonstrate writing style and document design and should not be taken to imply authorship by Strava or access to internal systems.\nLast modified: 17 November 2025\nGrade Adjusted Pace (GAP) estimates how fast you would have run on a flat route even if your run was actually on uphill, downhill or mixed grade terrain. By using GAP, runners can better compare paces across routes that have very different terrain profiles.\nSee also: Pace"
  },
  {
    "objectID": "posts/strava-gap-metric/index.html#where-to-find",
    "href": "posts/strava-gap-metric/index.html#where-to-find",
    "title": "Grade Adjusted Pace (GAP)",
    "section": "Where to find",
    "text": "Where to find\nYou can check your run‚Äôs GAP on both the Strava website and the mobile app (Android / iOS). You‚Äôll find it in the following places:\n\n\n\n\n\n\nTo Do\n\n\n\n[Get side-by-side screenshot of the GAP metric on a post-run analysis screen. There would be captions under each image: ‚ÄòMobile View ‚Äôon the left, ‚ÄôDesktop View‚Äô on the right]\n\n\nYour run‚Äôs analysis screen lets you evaluate your GAP across your full activity. You can even zoom in on key points for a closer look at your adjusted pace on any particularly nasty uphills.\nYour followers will also be able to view your GAP, so they can see how hard you really worked and give you the compliments you deserve."
  },
  {
    "objectID": "posts/strava-gap-metric/index.html#how-gap-works",
    "href": "posts/strava-gap-metric/index.html#how-gap-works",
    "title": "Grade Adjusted Pace (GAP)",
    "section": "How GAP Works",
    "text": "How GAP Works\nThe GAP model uses two inputs: the grade of the terrain and the pace adjustment factor derived from physiological research.\n\nGrade:\nStrava estimates the grade (steepness) throughout your run by using elevation data.\nSee also: Elevation\nPace Adjustment Factor:\nStrava‚Äôs Grade Adjusted Pace formula is based on research published in the Journal of Applied Physiology by Davies [@Davies1974; @Davies1980] and Minetti [@Minetti2002]. Over time, Strava‚Äôs engineering team has continued to build upon these studies. Broadly, the conclusions are:\n\nEffort is affected by the direction of steepness. Positive grades increase effort. Negative grades decrease it.\nEffort is affected by the level of steepness. In general, higher levels of steepness have larger effects on effort.\n\nCrucially, however, Strava‚Äôs analysis of athlete heart rate data has helped to quantify how much extra effort is expended on uphills or saved on downhills. For example, they found that:\n\nDownhills provide their greatest energy savings and pace increases at grades around -10%. Steeper than this, the positive effects begin to decrease.\n\nAt -18% downhills actually have a negative impact on your pace. This is because of a braking effect where runners must actively slow down.\n\nBy quantifying the relationship between effort and grade, Strava can apply a Pace Adjustment Factor that is based on grade. On perfectly flat 0% grade terrain, this factor will be 1.0.\nThe full range of adjustment factors that Strava applies to grades from -30% to +30% can be seen on this graph:\n\n\n\nCode\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# 1. Create the example data\ndata = {\n    'grade_percent': [\n        -30, -25, -20, -18, -15, -10, -9, -5, 0, \n        5, 10, 15, 20, 25, 30\n    ],\n    'adjustment_factor': [\n        1.52, 1.26, 1.06, 1.0, 0.93, 0.88, 0.88, 0.9, 1.0, 1.27, 1.66, 2.13, \n        2.65, 3.2, 3.74\n    ]\n}\n\n# 2. Create a DataFrame\ndf = pd.DataFrame(data)\n\n# 3. Plot\nfig, ax = plt.subplots()\n\nsns.lineplot(\n    data=df,\n    x='grade_percent',\n    y='adjustment_factor',\n    marker='o',  # Add markers for the data points\n    lw=2,        # Line width\n    ax=ax        # Tell seaborn to use our 'ax' object\n)\n\nax.set_ylim(0.5, 4)\nax.set_title('Grade Adjusted Pace Model', fontsize=16)\nax.set_xlabel('Gradient (%)', fontsize=12)\nax.set_ylabel('Pace Adjustment Factor', fontsize=12)\n\n# --- Add a reference line for \"flat\" ---\nax.axhline(\n    y=1.0, \n    color='grey', \n    linestyle='--', \n    lw=1.5\n)\nax.text(-32, 1.02, 'Flat Terrain', color='grey', fontsize=10)\n\n# --- Add callouts for key points ---\nax.annotate('Max downhill benefit occurs\\nat approx. -9%',xy=(-9, 0.88), ha='center', arrowprops=dict(facecolor='black', shrink=0.05), xytext=(-4, 2), fontsize=10, color='black', bbox=dict(boxstyle='round', fc='0.9'))\n\nax.annotate('Braking effect begins \\nat approx. -18%',xy=(-18, 1.0), ha='left', arrowprops=dict(facecolor='black', shrink=0.05), xytext=(-30, 3), fontsize=10, color='black', bbox=dict(boxstyle='round', fc='0.9'))\n\n# --- Final touches ---\nax.grid(True, linestyle=':', alpha=0.7)\n\n# --- Use as thumbnail ---\nfig.savefig(\"featured.png\", facecolor='white')\n\n\n\n\n\n\n\n\nFigure¬†1: Strava‚Äôs GAP model, showing pace adjustment factor vs.¬†grade.\n\n\n\n\n\nTo understand how the graph works, let‚Äôs look at the GAP calculations for a 7 minute mile run on a 5% gradient:\n1. Convert minutes/mile to seconds: \\(7 √ó 60 = 420\\)\n2. Divide by the uphill factor: \\(420 √∑ 1.27 ‚âà 331\\)\n3. Convert back to minutes: \\(331 √∑ 60 ‚âà 5:31\\)\nThe following table shows GAP values for common paces across different gradients.\n\n\n\nGrade %\nFactor\n6:00 mile\n7:00 mile\n8:00 mile\n\n\n\n\n-7.5\n0.89\n06:45\n07:53\n09:01\n\n\n-5.0\n0.90\n06:40\n07:47\n08:53\n\n\n-2.5\n0.95\n06:19\n07:22\n08:25\n\n\n0.0\n1.00\n06:00\n07:00\n08:00\n\n\n+2.5\n1.14\n05:16\n06:09\n07:01\n\n\n+5.0\n1.27\n04:44\n05:31\n06:18\n\n\n+7.5\n1.47\n04:05\n04:46\n05:27\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nGAP and Pace are identical on flat surfaces"
  },
  {
    "objectID": "posts/strava-gap-metric/index.html#how-to-interpret",
    "href": "posts/strava-gap-metric/index.html#how-to-interpret",
    "title": "Grade Adjusted Pace (GAP)",
    "section": "How to Interpret",
    "text": "How to Interpret\nüî∫ SCENARIO 1: You ran a net UPHILL route\n\nAverage Grade: +5.0%\nFactor: 1.27\nPace: 7:00/mile\nGAP: 5:31/mile\n\nYour pace was divided by a factor greater than 1 when you ran on uphill sections. This meant your GAP was faster than your Pace.\n‚ö° SCENARIO 2: You ran a net DOWNHILL route\n\nAverage Grade: ‚àí5.0%\nFactor: 0.90\nPace: 7:00/mile\nGAP: 7:47/mile\n\nYour pace was divided by a factor less than 1 when you ran on downhill sections. This meant your GAP was slower than your Pace.\n‚öñÔ∏è SCENARIO 3: You ran a FLAT or BALANCED route\n\nAverage Grade: 0%\nFactor: 1.0\nPace: 7:00/mile\nGAP: 7:00/mile\n\nYour pace was divided by 1 so it didn‚Äôt change.\n\n\n\n\n\n\nTip\n\n\n\nAlways check the elevation data. A route with constant ups and downs would be very tiring but could still result in a GAP which appears as if it were flat. For example, the Boston Marathon is notoriously challenging due to its uphill sections but is actually a net downhill course."
  },
  {
    "objectID": "posts/strava-gap-metric/index.html#limitations",
    "href": "posts/strava-gap-metric/index.html#limitations",
    "title": "Grade Adjusted Pace (GAP)",
    "section": "Limitations",
    "text": "Limitations\n\nGAP may indicate that a route was flat when it contained significant uphill and downhill sections.\nGAP does not adjust for the fatigue caused by effort spikes or uneven pacing on undulating terrain.\nGAP does not adjust for any other terrain features or technical difficulties, such as gravel. It only accounts for the gradient.\nGAP does not adjust for the additional stress on joints of downhill running."
  },
  {
    "objectID": "posts/strava-gap-metric/index.html#golden-rules",
    "href": "posts/strava-gap-metric/index.html#golden-rules",
    "title": "Grade Adjusted Pace (GAP)",
    "section": "Golden Rules",
    "text": "Golden Rules\nGAP is a helpful training tool. You can make more accurate assessments of your fitness level by minimising the confusion caused by hilly terrain. Just follow these golden rules to use it properly.\nUse GAP when:\n\nComparing your best 5 km times on different routes\nAssessing fitness trends when you run on varied terrain\nBenchmarking tempo run or interval times on new routes by comparing them to your old or existing routes\nYou have checked the Elevation profile to check if the route is Flat or Balanced\n\nDon‚Äôt rely on GAP when:\n\nRunning technical trails\nEvaluating injury risk from downhills\nMeasuring pacing discipline"
  },
  {
    "objectID": "posts/strava-gap-metric/index.html#references",
    "href": "posts/strava-gap-metric/index.html#references",
    "title": "Grade Adjusted Pace (GAP)",
    "section": "References",
    "text": "References\n\nTo Do\n[Fix the quarto bibtex referencing. It‚Äôs not working for some reason]"
  },
  {
    "objectID": "posts/post-relegation-attendance/index.html",
    "href": "posts/post-relegation-attendance/index.html",
    "title": "Fair-Weather Fans?",
    "section": "",
    "text": "I‚Äôm a Burnley fan. With our recent promotion to the Premier League we are firmly consolidated as a yoyo club par excellence - we rank joint-4th with Sunderland on the Yoyo-meter (below). So what better time to assess some of the impacts of relegation from the Premier League? Because it‚Äôs never too early to plan ahead.\nIn this article, I‚Äôll be exploring if, how and for how long Premier League relegation disrupts attendances. We‚Äôll also examine some mitigating factors. Does attractive football help maintain attendances? Is mid-table mediocrity worse for attendances than being in a relegation dogfight?\nThe dataset I have designed for this project combines a few different online resources and also engineers some variables. You can read about it and download it here."
  },
  {
    "objectID": "posts/post-relegation-attendance/index.html#methodology",
    "href": "posts/post-relegation-attendance/index.html#methodology",
    "title": "Fair-Weather Fans?",
    "section": "Methodology",
    "text": "Methodology\n\nData Collection\nFor this project, I gathered attendance, league position, and performance data for every club relegated from the Premier League, spanning a four-year period for each event:\n\nYear -1: The season before the Premier League relegation season.\nYear 0: The Premier League season that resulted in relegation.\nYear +1: The first season after relegation (in the Championship).\nYear +2: The second season after relegation.\n\n\n\n\n\n\n\nNote\n\n\n\nA temporary fifth year of data (Year +3) was programmatically generated to extract the league tier, which is used to determine the final outcome of the Year +2 season. After achieving that, the temporary Year +3 data was dropped.\n\n\n\nSources\n\nFor Attendance data, I referenced European-Football-Statistics.co.uk.\nFor both Position and Performance data I relied on the Fjelstul English Football Database, which is a comprehensive catalogue of English Football from 1888-2024. I used a small section from the standings dataset, but he also has datasets covering seasons, teams, matches, and appearances. Worth a look if you have a project in mind.\n\n\n\n\n\n\n\nNote\n\n\n\nDr.¬†Fjelstul‚Äôs database is copyrighted (‚Äú¬© 2024 Joshua C. Fjelstul, Ph.D.‚Äù) but accessible via the CC-BY-SA 4.0 license. I will also be making my own dataset available under the same CC-BY-SA 4.0 license.\n\n\n\n\n\nDataset\nIn addition to merging attendance data with position data and performance data, some key features of the dataset had to be engineered. I needed Year_vs_Relegation and Year_End_Outcome columns in order to group by season outcomes and to track attendance over time.\nFor my single source of truth dataset, I am using the raw values for performance (Points, Goals, etc.) and calculating per-game metrics as needed for analysis. Below is a snapshot of the final, tidy dataset.\n\nLimitations\nAs tidy as it is, there are still some pretty big limitations to this dataset:\nSeason-Level Granularity:\n- The dataset aggregates data at the season level, meaning any within-season events‚Äîsuch as managerial changes, mid-season form swings, or cup runs‚Äîare not captured.\nLoss of Match-Level Variability:\n- Attendance figures are averaged per season, so high- or low-attendance matches (e.g., local derbies) are smoothed out.\nExternal Influences Aren‚Äôt Captured (with the exception of COVID) - Factors such as weather, ticket pricing, fan protests, or extraordinary events (e.g., stadium closures) are not included. These could all contribute to unexplained variance in attendance. However, I do think that over a season, these sorts of things tend to balance themselves out. Except for COVID and stadium reconstructions, which both need special handling.\nHandling COVID-19\n- A quick note on the elephant in the stadium: the 2019-20 and 2020-21 seasons. Since many games were played with zero or partial attendance, including them as ‚Äú0‚Äù would catastrophically skew the averages. To prevent this, the data cleaning pipeline explicitly searches for any attendance data marked ‚ÄúCOVID‚Äù and converts it to a null value (pd.NA). All subsequent averaging functions automatically ignore these null values, so the analysis is not contaminated by seasons played behind closed doors.\nHandling Stadium Anomalies The data contains three major structural anomalies where attendance was dictated by stadium construction, not fan sentiment or on-pitch performance:\n\nMiddlesbrough (1993-94): Attendance artificially plummeted due to a stadium rebuild.\nSunderland (1997-98): Attendance saw a massive, artificial spike from moving to the new Stadium of Light.\nLeicester City (2002-03): A similar spike occurred when the club moved to the Walkers Stadium (now called the King Power Stadium).\n\nTo prevent these outliers from skewing my interpretations, these specific team-seasons were identified. Unless I specifically mention their inclusion, you can safely assume they were filtered out of the analysis.\n\n\nDownloadable\nIf you still want the dataset for analysis after all that, or you‚Äôre wondering why I keep calling things tidy, then check out Too Messy to Melt for a technical guide to how this dataset was constructed. Or you can inspect the data dictionary and grab the downloadable dataset straight from my GitHub."
  },
  {
    "objectID": "posts/post-relegation-attendance/index.html#analysis",
    "href": "posts/post-relegation-attendance/index.html#analysis",
    "title": "Fair-Weather Fans?",
    "section": "Analysis",
    "text": "Analysis\n\nIncreased attendance after relegation?\nLet‚Äôs start on a positive note. On 10 occasions, teams managed to increase their average attendance in the first season (Y+1) immediately following relegation.\n\n\n\n\n\n\n\nTeam\nAttendance (Y0)\nAttendance (Y+1)\nChange (%)\n\n\n\n\nSunderland\n20865\n33492\n60.52\n\n\nLeicester City\n19835\n29231\n47.37\n\n\nNottingham Forest\n21910\n23051\n5.21\n\n\nIpswich Town\n24426\n25455\n4.21\n\n\nBurnley\n19399\n19953\n2.86\n\n\nNewcastle United\n49754\n51106\n2.72\n\n\nNorwich City\n24350\n24952\n2.47\n\n\nCrystal Palace\n14992\n15248\n1.71\n\n\nLuton Town\n11244\n11420\n1.57\n\n\nMiddlesbrough\n29848\n29994\n0.49\n\n\n\n\n\nAnd I have to give a shoutout to Burnley and, indeed, to Vincent Kompany because he certainly galvanised the supporters that season.\nA couple teams really jump out. Both Sunderland and Leicester City moved into new stadia the year after their relegation, and this gave them a considerable bump. They must have been absolutely packing out their stadia the season prior and had supporters banging down the doors to get in. Sunderland even managed to add over 5,000 supporters to their tally the season after relegation, despite the fact that they were still stuck in the Championship. Leicester also increased attendances in 2003-04, by 1,600 to 30,983. But they spent that season in the Premier League, so it‚Äôs less startling to see an increase.\nNewcastle also catch the eye, but not just because their 51,106 fans in 2016-17 is an extraordinary number - everyone knows Newcastle is a football-mad city. What‚Äôs truly insightful is comparing their two most recent relegations.\n\nAfter relegation in 2009, the club saw a significant 11% drop in average attendance.\nAfter relegation in 2016-17, The club saw a 2.7% increase in attendance.\n\nThat‚Äôs 13.7-point swing. The club was massive in both scenarios, so ‚Äúbig club‚Äù is a constant. The most obvious variable is ‚Äúvibes.‚Äù\nAt the end of 2008-09 Newcastle‚Äôs all-time record goalscorer and local lad Alan Shearer had stepped up to try and save Newcastle. He only had 8 games to do it in. No matter the outcome, he was supposed to stay on as manager into the next season. But they got relegated and he didn‚Äôt get offered a contract for the next season. There‚Äôs no doubt that this was a low point between Newcastle fans and their owner Mike Ashley. And this was borne out in the 2009-10 attendances.\n2016-17 was the polar opposite. Similar to how Burnley fell under the spell of Vincent Kompany in 2022/23, Newcastle fans had a great relationship with Rafael Benitez, even if Mike Ashley was still as loathed as ever. Benitez was hired towards the end of their 2015/16 relegation season and it was considered quite a coup to attract this Champions League-winning manager to a Championship-bound club. So the fans showed their appreciation during his first full season in charge with record-breaking attendances."
  },
  {
    "objectID": "posts/post-relegation-attendance/index.html#anomalies",
    "href": "posts/post-relegation-attendance/index.html#anomalies",
    "title": "Fair-Weather Fans?",
    "section": "Anomalies",
    "text": "Anomalies\nThose positive stories are, unfortunately, anomalies. And they are not the only ones. A box plot of all post-relegation data (Y+1 and Y+2) shows the wild variance in outcomes.\n\n\n\n\n\nDistribution of attendance change (Y+1 & Y+2) by outcome, including all outliers and sample sizes.\n\n\n\n\nThe plot above clearly shows several extreme statistical outliers (the dots) that are skewing the data. To understand what they are, we can use the 1.5 * IQR rule (the same logic the box plot uses) to print a list of them.\n\nOutlier Hunt Using the 1.5 * IQR Rule\n\n\n\n\n\n\n\nOutcome\nTeam\nSeason\nYear\nChange vs Y0 (%)\n\n\n\n\nSurvived\nSunderland\n1998-99\n2\n+85.7\n\n\nSurvived\nSunderland\n1997-98\n1\n+60.5\n\n\nPromoted\nLeicester City\n2003-04\n2\n+56.2\n\n\nPromoted\nLeicester City\n2002-03\n1\n+47.4\n\n\nPromoted\nBolton Wanderers\n1997-98\n2\n+29.4\n\n\nPromoted\nSunderland\n2007-08\n2\n+27.8\n\n\nPromoted\nFulham\n2019-20\n1\n-25.3\n\n\nPromoted\nHull City\n2015-16\n1\n-27.0\n\n\nPromoted\nBirmingham City\n2008-09\n1\n-27.1\n\n\nSurvived\nWimbledon\n2000-01\n1\n-53.9\n\n\nSurvived\nWimbledon\n2001-02\n2\n-59.4\n\n\n\n\n\n\n\nCase-by-Case Anomaly Handling\nThis list gives us a clear action plan. To understand the true relationship between performance and attendance, we must filter out cases where attendance was driven by external structural factors, not fan behavior.\n\n\n\n\n\n\n\n\n\n\n\nRelegation Event\nYear\nChange\nOutlier Type\nDecision\nReason\n\n\n\n\nSunderland 1996-97\nY+1, Y+2\n+61%, +86%\nStadium Anomaly\nRemove\nMoved to the new, much larger Stadium of Light.\n\n\nLeicester City 2001-02\nY+1, Y+2\n+47%, +56%\nStadium Anomaly\nRemove\nMoved to the new Walkers (King Power) Stadium.\n\n\nBolton Wanderers 1995-96\nY+2\n+29%\nStadium Anomaly\nRemove\nY+2 (1997-98 season) was their first in the new Reebok Stadium.\n\n\nMiddlesbrough 1992-93\nY+1\n-38%\nStadium Anomaly\nRemove\nAttendance nosedived during a stadium rebuild.\n\n\nWimbledon 1999-2000\nY+1, Y+2\n-54%, -59%\nToxicity\nKeep\nTo be continued‚Ä¶\n\n\nHull City 2014-15\nY+1\n-27%\nToxicity\nKeep\nTo be continued‚Ä¶\n\n\nBirmingham City 2007-08\nY+1\n-27%\nToxicity\nKeep\nTo be continued‚Ä¶\n\n\n\nNow, with the data properly filtered, let‚Äôs look at the real story.\nAnd we may as well start with that Toxicity factor I mentioned above."
  },
  {
    "objectID": "posts/post-relegation-attendance/index.html#the-toxicity-factor-when-loyalty-snaps-and-when-it-doesnt",
    "href": "posts/post-relegation-attendance/index.html#the-toxicity-factor-when-loyalty-snaps-and-when-it-doesnt",
    "title": "Fair-Weather Fans?",
    "section": "The Toxicity Factor: When Loyalty Snaps (and When It Doesn‚Äôt)",
    "text": "The Toxicity Factor: When Loyalty Snaps (and When It Doesn‚Äôt)\nOn-pitch performance isn‚Äôt the only driver. The data shows that a toxic or broken relationship between a club‚Äôs owners and its fans can act as a powerful accelerant for an attendance collapse.\nThese aren‚Äôt just ‚Äúbad vibes‚Äù; they are measurable, real-world events:\nHull City (2014-15): The -27% drop in Y+1 wasn‚Äôt just about relegation. It directly coincided with a fan mutiny over the owners‚Äô deeply unpopular attempt to rebrand the club as ‚ÄúHull Tigers.‚Äù\nBirmingham City (2007-08): A similar story. Their -27% nosedive in Y+1 was fueled by widespread fan protests calling for the board to resign.\nNewcastle (2009-10 vs.¬†2016-17): This is the perfect A/B test. In both 2009 and 2016, the club had the same toxic ownership under Mike Ashley.\nIn 2009-10, the vibe was poisonous. The result? A significant 11% drop in attendance.\nIn 2016-17, a different ‚Äúvibe‚Äù won. Hiring (and keeping) Rafa Benitez was such an unexpected coup that his popularity papered over the cracks, galvanizing the fanbase and leading to a 2.7% increase.\nWimbledon (1999-2000): This is the ultimate case study. They were already a ‚Äúhomeless‚Äù club, playing at Crystal Palace‚Äôs Selhurst Park during their Y0 relegation season. Their baseline attendance was already depressed. When they lost their Premier League status, attendance collapsed by -59%. The showpiece occasion of a Premier League game seems to have been the last thread holding that displaced fanbase together. When it snapped, so did the club."
  },
  {
    "objectID": "posts/post-relegation-attendance/index.html#a-results-business",
    "href": "posts/post-relegation-attendance/index.html#a-results-business",
    "title": "Fair-Weather Fans?",
    "section": "A Results Business",
    "text": "A Results Business\nNext up, we‚Äôll look at our Year_End_Outcome variable. Let‚Äôs plot the attendance change over time, grouping teams by whether they were Promoted, Survived, or Relegated in their first post-relegation season.\n\n\n\n\n\nAverage attendance change (anomalies removed) relative to the relegation season (Y0), grouped by the team‚Äôs outcome in their first post-relegation season (Y+1).\n\n\n\n\nIrrespective of season outcome, relegated teams on average lose fans. And there seems to be a clear correlation between team performance and attendance. Moreover, it does seem that performance affects attendances.\nPromoted (Green Line): Teams that bounce straight back (like Burnley) see their Y+1 attendance drop minimized to just -8.6%. By Y+2, they are back in the Premier League, and attendance recovers to surpass its pre-relegation level by 2%.\nSurvived (Blue Line): Teams that ‚Äúsurvive‚Äù and stay in the Championship see a much larger initial drop of -17.2%. Worse, by Y+2, that optimism fades and attendance dwindles further to -21.6%.\nRelegated (Orange Line): Teams that enter freefall and plummet into League 1 see a catastrophic -28% drop in Y+1, which slightly recovers to -24% in Y+2."
  },
  {
    "objectID": "posts/post-relegation-attendance/index.html#would-champagne-football-help",
    "href": "posts/post-relegation-attendance/index.html#would-champagne-football-help",
    "title": "Fair-Weather Fans?",
    "section": "Would champagne football help?",
    "text": "Would champagne football help?\nIf you‚Äôre stuck in the Championship, can you at least keep the fans entertained with attacking football?\nTo test this, I‚Äôve plotted Goals_For_Per_Game against the percentage change in attendance for all post-relegation seasons (Y+1 and Y+2), again grouped by the team‚Äôs outcome and with the stadium anomalies removed.\n\n\n\n\n\nScatter plots (all structural anomalies removed) showing the relationship between attacking football and the percentage change in attendance.\n\n\n\n\nThe answer seems to be: yes, but only if you have nothing else to play for.\nFor Survived teams, there is a fairly clear positive relationship. If a team is destined for another year of mid-table Championship football, entertainment value (scoring goals) seems to help keep traffic coming through the turnstiles."
  },
  {
    "objectID": "posts/post-relegation-attendance/index.html#conclusions",
    "href": "posts/post-relegation-attendance/index.html#conclusions",
    "title": "Fair-Weather Fans?",
    "section": "Conclusions",
    "text": "Conclusions\n\nTeams can typically expect to lose 16-22% of their attendance after relegation if they don‚Äôt bounce straight back, and that drop accelerates in the second year.\nIf you are on track for promotion, losses are minimized to ~8% and attendance fully recovers upon returning to the Premier League.\n‚ÄúVibes‚Äù (like a popular manager) and ‚Äústyle‚Äù (attacking football) seem to be real factors, but their effect is most visible for teams stuck in mid-table, where the on-pitch result isn‚Äôt exciting enough on its own.\nAnd if you are on track for League 1, these losses are considerably higher\nRelegation doesn‚Äôt automatically mean fan abandonment. Context matters: management, entertainment value, stadium capacity, and hope for promotion all play a role."
  },
  {
    "objectID": "posts/post-relegation-attendance/index.html#sources-1",
    "href": "posts/post-relegation-attendance/index.html#sources-1",
    "title": "Fair-Weather Fans?",
    "section": "Sources:",
    "text": "Sources:\nFjelstul, Joshua C. ‚ÄúThe Fjelstul English Football Database v1.1.0.‚Äù May 26, 2024. https://www.github.com/jfjelstul/englishfootball\nEuropean-Football-Statistics.co.uk\nThumbnail image courtesy of Jaroslav A. Pol√°k from Brno, Czech Republic, CC0, via Wikimedia Commons"
  },
  {
    "objectID": "posts/currys-copywriting-samples/index.html",
    "href": "posts/currys-copywriting-samples/index.html",
    "title": "Currys",
    "section": "",
    "text": "A compilation of some ecommerce copy I wrote while working as a copywriter for Currys. I wrote about everything and anything - particularly computing.\nSome links will inevitably break over time. Increasingly, these products are no longer on the main Currys site. But archived products often sit on Currys Business - the ugly duckling sibling site - to wither and rot. Where I‚Äôve used a Currys Business link, the neglected product would be especially grateful to receive your visit.\nMy name isn‚Äôt on any of these, but I promise I wrote them!\nLEDGER Nano X Hardware Wallet For Crypto \n\nSHOKZ OpenRun Bone Conduction Sports Headphones \n\nFootball Manager 24 \n\nSpongeBob SquarePants: The Cosmic Shake\n\n\nASUS ROG Strix SCAR 18‚Äù Gaming Laptop\n\n\n\nThumbnail image courtesy of FutureBrand Currys PLC, CC BY-SA 4.0, https://creativecommons.org/licenses/by-sa/4.0, via Wikimedia Commons"
  },
  {
    "objectID": "assets/archived_md/index.html",
    "href": "assets/archived_md/index.html",
    "title": "Fair-Weather Fans?",
    "section": "",
    "text": "Project To-Dos:\n\n\n\n\n\n\nMake a Shiny for Python dashboard\nAdd a box plot with Destination: PL relegation, Championship survival, Championship promotion, Championship relegation on the x axis # TODO\nCurrently, my tables are just built from data I crunched in Excel a while back. I want to revamp all of this with Python # TODO\nMaybe add formal hypothesis testing and a regression model # TODO\nAdd more leagues. I am expecting things to stabilise once you are out of the Prem and bouncing around the Football League # TODO\nRe-draft of the text\nI‚Äôm a Burnley fan. And in honour of our impending promotion to the Premier League and consolidation as a yoyo club par excellence, I thought it would be a good time to assess the impact of relegation from the Premier League on attendance figures. Because it‚Äôs never too early to plan ahead."
  },
  {
    "objectID": "assets/archived_md/index.html#methodology",
    "href": "assets/archived_md/index.html#methodology",
    "title": "Fair-Weather Fans?",
    "section": "Methodology",
    "text": "Methodology\nFor this project, I gathered attendance data for every relegated club in the season they were relegated, and in the 2 seasons following their relegation. I also checked what league they were in for their 2nd year post-relegation. Had they been promoted at the first attempt? Spent another season in the Championship, or plummeted into League 1. I gathered all of this data from European-Football-Statistics.co.uk."
  },
  {
    "objectID": "assets/archived_md/index.html#analysis",
    "href": "assets/archived_md/index.html#analysis",
    "title": "Fair-Weather Fans?",
    "section": "Analysis",
    "text": "Analysis\n\nIncreased attendance after relegation?\nLet‚Äôs start on a positive note. On 10 occasions, teams managed to increase their average attendance following relegation.\n\n\n\n\n\n\n\n\n\n\nRelegated Team (Season)\nAttd.\nYear After\nAttd. year after\nLoss/Gain %\n\n\n\n\nSunderland (96/97)\n20,865\n1997-98\n33,492\n60.5%\n\n\nLeicester City (01/02)\n19,835\n2002-03\n29,231\n47.4%\n\n\nNottingham Forest (92/93)\n21,910\n1993-94\n23,051\n5.2%\n\n\nIpswich Town (01/02)\n24,426\n2002-03\n25,455\n4.2%\n\n\nBurnley (21/22)\n19,399\n2022-23\n19,953\n2.9%\n\n\nNewcastle United (15/16)\n49,754\n2016-17\n51,106\n2.7%\n\n\nNorwich City (04/05)\n24,350\n2005-06\n24,952\n2.5%\n\n\nCrystal Palace (94/95)\n14,992\n1995-96\n15,248\n1.7%\n\n\nLuton Town (23/24)\n11,244\n2024-25\n11,420\n1.6%\n\n\nMiddlesbrough (96/97)\n29,848\n1997-98\n29,994\n0.5%\n\n\n\nAnd I have to give a shoutout to Burnley and, indeed, to Vincent Kompany because he certainly galvanised the supporters that season.\nA couple teams really jump out. Both Sunderland and Leicester City moved into new stadia the year after their relegation, and this gave them a considerable bump. They must have been absolutely packing out their stadia the season prior and had supporters banging down the doors to get in. Sunderland even managed to add over 5,000 supporters to their tally the season after relegation, despite the fact that they were still stuck in the Championship. Leicester also increased attendances in 2003-04, by 1,600 to 30,983. But they spent that season in the Premier League, so it‚Äôs less startling to see an increase.\nNewcastle also catch the eye. 51,106 fans during the 2016-17 is quite extraordinary. Newcastle‚Äôs fanbase has a reputation for diehard loyalty. It‚Äôs why many neutrals were happy to see them bought by the Saudis, despite misgivings about sportwashing. Indeed, Newcastle also have the second-highest post-relegation attendance - 43,388 during the 2009-2010 season. That particular season did see an 11% drop on the previous year‚Äôs PL average. And the contrast between 2016-17 and 2009-10 is enlightening. Similar to how Burnley fell under the spell of Vincent Kompany in 2022/23, Newcastle fans had a great relationship with Rafael Benitez - their manager from 2016 to 2019. Hired towards the end of their 2015/16 relegation season, it was considered quite a coup to attract Benitez to a Championship-bound club. And the fans showed their appreciation during his first full season in charge with record-breaking attendances.\nTypically, we start to see the cracks in season 2 outside the top flight. Filtering out teams like Leicester who were promoted at the first attempt and had Premier League fixtures to pull in the fans, only 6 teams see attendance figures in the black by season 2.\n\n\n\n\n\n\n\n\n\n\n\nRelegated Team (Season)\nAttd.\nAttd. year after\nLoss/Gain %\nAttd. 2 yrs. after\nLoss/Gain % 2 yrs.\n\n\n\n\nSunderland (96/97)\n20,865\n33,492\n60.5%\n38,745\n86%\n\n\nMiddlesbrough (92/93)\n16,724\n10,400\n-37.8%\n18,702\n11.8%\n\n\nCrystal Palace (94/95)\n14,992\n15,248\n1.7%\n16,085\n7.3%\n\n\nManchester City (95/96)\n27,869\n26,753\n-4.0%\n28,196\n1.2%\n\n\nNorwich City (04/05)\n24,350\n24,952\n2.5%\n24,545\n0.8%\n\n\nIpswich Town (01/02)\n24,426\n25,455\n4.2%\n24,520\n0.4%\n\n\n\nAgain, we have some anomalies. Middlesborough‚Äôs attendance nosedived in 1993-94 but they were undergoing a stadium rebuild. Basically, they had more stadium 2 years later. By 2017-18, Middlesborough were hosting 25,544 fans a game in the Championship and over 30,000 during their stint for the preceding year‚Äôs stint in the Prem. So their 10,400 fan turnout - heck, even their 18,702 fan turnout, are merely reflective of stadium constraints and not reflective of their true fanbase.\n\n\nNosedives\nThis will include a mini investigation into Middlesborough and Oldham to find out why their attendances plummeted. I think there were explanatory factors.\n\n\nAnd in general?\nOn average, attendance falls significantly after relegation. The below table shows a 1st-year average decrease of 13.72%. And it shows that in the second year, there is an average decrease of 12.34%.\n\n\n\n\n\n\n\n\nLeague\nYear After Avg. Loss/Gain %\n2 yrs After Avg. of Loss/Gain %\n\n\n\n\nChampionship\n-13.72%\n-19.15%\n\n\nLeague 1\nN/A\n-23.80%\n\n\nPL\nN/A\n5.36%\n\n\nOverall\n-13.72%\n-12.34%\n\n\n\nEXCLUDING MIDDLESBOROUGH, LEICESTER & SUNDERLAND\n\n\n\n\n\n\n\n\nLeague\nYear After Avg. Loss/Gain %\n2 yrs After Avg. of Loss/Gain %\n\n\n\n\nChampionship\n-13.45%\n-21.49%\n\n\nLeague 1\nN/A\n-23.80%\n\n\nPL\nN/A\n3.24%\n\n\nOverall\n-14.98%\n-14.59%\n\n\n\nI think this table excluding Middlesborough, Leicester and Sunderland who introduce anomalies related to stadium constructions may be a better reference for this data. Superficially, the above data is reassuring. If you just look at the overalls, then it would seem attendances stabilise in Year 2 after relegation. You lose 15% of your attendance immediately after relegation, but at least it doesn‚Äôt get worse. But it does.\nIf you didn‚Äôt get promoted to the Premier League at the first time of asking and spend a 2nd year in the Championship, then you can expect to lose a further 8% of your Premier League attendance. And if you get relegated to League 1, that jumps above 10%. So it seems teams will stick with a team more resolutely in the year after their relegation, likely hoping for a successful season and a swift return. By Year 2, that optimism may fade and attendance figures dwindle still further. Let‚Äôs probe that performance factor further.\n\n\nDoes performance affect attendance?\nThe below table shows how the outcome of your first season post-relegation can impact attendance figures during that season.\n\n\n\nDestination during Championship Season\nAverage of Loss/Gain %\n\n\n\n\nChampionship\n-16.58%\n\n\nLeague 1\n-28.16%\n\n\nPL\n-5.84%\n\n\n2023/24 teams without year 2 data\n-4.07%\n\n\n¬†¬†¬†Burnley\n-7.29%\n\n\n¬†¬†¬†Luton Town\n1.57%\n\n\n¬†¬†¬†Sheffield United\n-6.47%\n\n\n\nEXCLUDING MIDDLESBOROUGH (93/94), LEICESTER (02/03) & SUNDERLAND (97/98)\n\n\n\nDestination during Championship Season\nAverage of Loss/Gain %\n\n\n\n\nChampionship\n-17.53%\n\n\nLeague 1\n-28.16%\n\n\nPL\n-8.15%\n\n\n2023/24 teams with unknown destination\n-4.07%\n\n\n¬†¬†¬†Burnley\n-7.29%\n\n\n¬†¬†¬†Luton Town\n1.57%\n\n\n¬†¬†¬†Sheffield United\n-6.47%\n\n\n\nIf your club isn‚Äôt on track to bounce straight back, then they can expect to lose around 17% of the previous years‚Äô attendance. And if they are heading for back-to-back relegations, with a freefall to League 1, expect losses of 28.16%. If, however, they are in the hunt for promotion then the losses are considerably less. Teams bound for the Premier League only lose 5.84% (8.15% excluding the new-stadium teams). As you can see, the above data also excludes teams who were relegated in 2023/24 - Burnley, Luton, Sheffield United. However, I think it‚Äôs best to include them. Luton are likely to be relegated, Burnley are likely to be promoted, and Sheffield United will probably just miss out on the top 2 and console themselves with the playoffs. Since all 3 clubs have spent the entire season on these trajectories, it‚Äôs safe enough to incorporate their impact on the season‚Äôs attendances. So I will include them as Luton: relegated to League 1; Burnley and Sheffield United promoted to the Premier League.\nWith Burnley & Sheffield United as PL, and Luton as League 1\n\n\n\nDestination during Championship Season\nAverage of Loss/Gain %\n\n\n\n\nOverall\n-13.72%\n\n\nChampionship\n-16.58%\n\n\nLeague 1\n-20.73%\n\n\nPL\n-5.92%\n\n\nGrand Total\n-13.72%\n\n\n\nWith Burnley & Sheffield United as PL, and Luton as League 1. EXCLUDING MIDDLESBOROUGH (93/94), LEICESTER (02/03) & SUNDERLAND (97/98)\n\n\n\nDestination during Championship Season\nAverage of Loss/Gain %\n\n\n\n\nOverall\n-14.98%\n\n\nChampionship\n-17.53%\n\n\nLeague 1\n-20.73%\n\n\nPL\n-8.05%\n\n\nGrand Total\n-14.98%\n\n\n\nLuton really buck the trend for League 1-destined sides. And because there are so few teams who are relegated from the Premier League to League 1 in consecutive seasons, their outlier status has a huge impact on the data, dropping the averages by almost 8%. But can Luton really be considered anomalous when the data population is so small? In my view, yes. First of all, Luton had an emotional relegation season. Their captain Tom Lockyer suffered a cardiac arrest mid-game. Fortunately, he survived and has been on a road to recovery ever since with the view to playing again. Moreover, Luton battled very bravely against relegation despite these traumatising events and despite being financial minnows. Luton were a uniquely united club during their relegation season. However, that is not the only explanation. The other is that Luton are another stadium-constrained side. Kenilworth Road is famously tiny, and was a peculiar relic among Premier League stadiums. Luton have received approval for a stadium rebuild that will double its capacity. Based on their increased attendances post-relegation, Luton are another case of a club where demand has exceeded supply for some time.\nJust a quick note on Burnley, who were in the black during their Kompany-led campaign but have lost almost 8% this season. There are a few factors at play. First, morale sank during Kompany‚Äôs PL season. Burnley were truly awful and the core of their Championship-winning side was cast aside in favour of new recruits - an inexplicable decision in the view of many fans. Moreover, ALK capital - the ownership group - made some ill-judged and patronising comments to supporters for not bringing a positive enough atmosphere to Turf Moor. In a nutshell, the mood was bleak by the end of 2022-23. Kompany‚Äôs departure and subsequent replacement by Scott Parker failed to excite fans. Nor did selling half the first team squad and sitting through a million 0-0 draws. Despite the successful campaign, Parker-ball has been a bit of a slog. Sidenote: I was a huge Parker skeptic at first but I think he has brought the solidity Burnley needed and, as the season has gone on, a more cohesive team has taken shape, the football has yielded more goals and the fanbase has gotten on side. In any case, this all goes to highlight that there are complexities behind the averages I am presenting here."
  },
  {
    "objectID": "assets/archived_md/index.html#conclusions",
    "href": "assets/archived_md/index.html#conclusions",
    "title": "Fair-Weather Fans?",
    "section": "Conclusions",
    "text": "Conclusions\n\nTeams can typically expect to lose 12 to 15% of their attendance after relegation\nIf you are on track for Promotion, these losses are lessened\nIf you are on track to stay in the Championship, these losses are slightly higher\nAnd if you are on track for League 1, these losses are considerably higher\nInvestigating the outliers in the dataset tends to reveal mitigating circumstances. Often these relate to stadium builds, but in other cases - like Newcastle and Burnley - it is just vibes at play. To really understand the data I would dig into each relegated team a little more to understand what underlying factors affect other teams because it‚Äôs possibly more nuanced than relegation = fanbandonment.\n\n\nThumbnail image courtesy of Jaroslav A. Pol√°k from Brno, Czech Republic, CC0, via Wikimedia Commons"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Eoin Dignan",
    "section": "",
    "text": "My name is Eoin, but throughout high school I was known exclusively as Diggy.\nI‚Äôm an MSc Data Science student (part-time) with an expected completion in 2027.\nMy background is in ecommerce copywriting, teaching & special needs care. Here is my resume.\n\n\n Miscellaneous Certificates\n\n\nTechSmith\nCamtasia\nSnagit\nSnagit - Techniques for Creating Training Materials\nSnagit - Techniques for Technical Documentation\n\n\n\nCoding:\nLearn Python 3 Skill Path (Codecademy)\nDataCamp Python Certificates\nDataCamp R Certificates\nDataCamp SQL Certificates\n\n\n\nBusiness Intelligence:\nDataCamp Power BI & Excel Certificates\n\n\n\nSEO & Marketing:\nGet Started Using Google Analytics (GA4)\nSemrush Academy SEO Principles: An Essential Guide for Beginners\n\n\n\nTeaching:\nInternational House Certificate in Teaching Young Learners and Teenagers (IHCYLT)\nCertificate in Teaching English to Speakers of Other Languages"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Diggy Digs Data",
    "section": "",
    "text": "Too Messy to Melt\n\n21 min\n\nDownloadable attendance churn dataset and walkthrough of its creation - from messy and manual Excel to a tidy and reproducible Python pipeline.\n\n\n\nDec 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Winner Takes Them All (Project Map with Power BI Dashboard)\n\n2 min\n\nA penalty-won-adjusted goals metric, a demo Power BI dashboard, and a roadmap toward a refreshable data pipeline.\n\n\n\nDec 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrade Adjusted Pace (GAP)\n\n8 min\n\nGrade Adjusted Pace estimates how fast you would have run on a flat route even if your run was on varied grades.\n\n\n\nNov 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nFair-Weather Fans?\n\n17 min\n\nDishing the data dirt on post-relegation loyalty.\n\n\n\nNov 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nScraperFC API Documentation\n\n5 min\n\nAn example of API technical writing. Documents a method from the ScraperFC package (Python). Covers parameters, return types, workflow examples, error handling, versioning‚Ä¶\n\n\n\nNov 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo Fear At That Age\n\n30 min\n\nTesting if there‚Äôs merit to the claim that young players are fearless.\n\n\n\nSep 29, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurrys\n\n1 min\n\nWriting samples from my days as a copywriter at tech retailer Currys.\n\n\n\nSep 30, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/no-fear-at-that-age/index.html",
    "href": "posts/no-fear-at-that-age/index.html",
    "title": "No Fear At That Age",
    "section": "",
    "text": "‚ÄòThere‚Äôs no fear at that age‚Äô is a familiar refrain from pundits. The idea goes that young players are naive, innocent; they take risks, they express themselves, and in an ‚Äòignorance is bliss way‚Äô they don‚Äôt show nerves the way older players do - or something.\nI guess the fearlessness theory rests on the presumption that young players think they have all the time in the world so a few blunders early on in their career won‚Äôt be the end of it. Or, there is so little pressure applied on them relative to senior players that they play with freedom and can ‚Äòexpress themselves‚Äô. I can understand that to a certain extent, although young players could easily go in the other, overawed direction. 18 year old me would definitely have fallen into the shitting myself camp. But then, it could be argued that I don‚Äôt have the mentality of an elite athlete.\nNevertheless, I‚Äôve always been skeptical. They are young adults, not toddlers. And loads of promising young careers go up in smoke; the consequences for these players‚Äô lives are devastating. Look at Jose Baxter, for example. I would imagine most young players have seen enough academy cohort colleagues fall by the wayside that they are acutely aware of their vulnerability. So I wanted to dig into this throwaway comment from pundits and find some way to interrogate it statistically.\nThe metric that is the easiest to isolate as a corollary for fear is the penalty. That‚Äôs because another fairly common idea is that every elite player should be able to tuck away a penalty. And that, 12 yards from goal, it is nerves rather than technique which undoes the pro player. While the best way to explore fear would be penalty shootout data - where every single kick is critical - I haven‚Äôt got that and will normal-time penalties as a proxy. Of course, these don‚Äôt have quite the same almighty importance but they still tell us something about the effects of nerves.\nThis is part of a series of analyses I‚Äôm doing where I fixate on penalties. It just drives me crazy how prevalent they are. It increasingly like every final is decided on penalties and every match a penalty is awarded. And it‚Äôs not just because of VAR. These increases have been ongoing for some time. See Figure¬†1. Or the interactive version Figure¬†2, though I haven‚Äôt added many leagues so there‚Äôs not much to play around with. At time of writing, Harry Kane is having the season of his life - so the story goes - with 14 goals in 7 games. Astonishing, yes, but 6 of those have been penalties‚Ä¶ Without penalties he‚Äôs at 8 in 7, which is still very good but well short of his current Dixie Dean trajectory. Anyway, I digress. If you‚Äôre interested, my main project is this one:\n\nWhat would happen if players who won the penalties were the only ones who got to take them? https://eoind.github.io/analytics/football/penalty_takers/\nAnd now for‚Ä¶ are young players really fearless? What does the penalty data say? (read on to find out!)\n\n\n\n\n\n\n\n\n\nFigure¬†1: Average penalties per match over time, by league (with global trend)\n\n\n\n\n\n\n\n\n\n\n\n\n        \n        \n        \n\n\n(a)\n\n\n\n\n\n\n                            \n                                            \n\n\n(b)\n\n\n\n\n\nFigure¬†2"
  },
  {
    "objectID": "posts/no-fear-at-that-age/index.html#penalty-sampling",
    "href": "posts/no-fear-at-that-age/index.html#penalty-sampling",
    "title": "No Fear At That Age",
    "section": "Penalty sampling",
    "text": "Penalty sampling\nI have whipped up the following (courtesy of Stathead / FBref):\n\nEvery normal time penalty taken in the Premier League - in other words, since the 1992/1993 season\nEvery normal time penalty taken in the Champions League since the 1999/2000 season\nEvery normal time penalty taken in La Liga since the 1999/2000 season\n\n\n\n\nLeague\nTotal Penalties\n\n\n\n\nPremier League\n2892\n\n\nLa Liga\n2956\n\n\nChampions League\n925\n\n\nTotal\n6773"
  },
  {
    "objectID": "posts/no-fear-at-that-age/index.html#age-bands",
    "href": "posts/no-fear-at-that-age/index.html#age-bands",
    "title": "No Fear At That Age",
    "section": "Age bands",
    "text": "Age bands\nFinally, I have constructed some age groupings. See . This is in order to prevent small samples for different ages giving unreliable values. For example, there is a 20% difference in the success rate for La Liga 19 year-olds compared 20 year-olds. However, given these age groups have relatively few attempts it‚Äôs easy for the data to get a little wild.\nI think the groups I have created are fairly logical. At the top and bottom end we‚Äôve got open intervals - we can have players from 0 to 20; though the youngest penalty taker in this data is 17. And our 33+ group can go to infinity. Though the oldest penalty taker is .. This group are called No Fear At That Age? Because it‚Äôs the age when expectations are minimal, you are at your most naive, innocent, etc. And the elder statesmen are called Cherry on Top. I would theorise that they also have a bit less pressure, because they have already had a good career, and nobody is looking at their performance as a measure of their potential. They are a known quantity by this point.\nThey sandwich 3-year age bands. 21-23 could be the most pressurised age. That‚Äôs the point at which many wonderkid careers have gone awry - think Bojan Krkic. It‚Äôs the moment when you need to step up, mature, realise your potential and be consistent. Otherwise, a journeyman career in the lower leagues could await you. Then 24-26 could constitute the beginning of a player‚Äôs peak years. 27-29 would often be considered, depending a little on position, the absolute peak years of the average player. 30-32 has proven very fruitful for many players too. However, the perspective on these players definitely shifts. At this point, pressure amplifies because pundits and fans are often questioning whether you are ‚Äòpast it‚Äô, whether you should get a multi-year contract renewal or not. Just look at Mo Salah. In 2024/2025 he has having a career year but, at the age of 32, Liverpool have spent all season agonising about whether to give him a commensurate contract because of his age.\n\nCaveat\nOne enormous caveat, however, is that the ages provided by Stathead simply use the player‚Äôs age at the commencement of the season, not their age at the time of taking a penalty. Consequently, the oldest penalty taker in the dataset is Teddy Sheringham. He appears as 39 in my dataset, but he had recently turned 40 when he missed a final-day penalty for West Ham against Tottenham in the 2005/06 season. Jorge Molina also appears as 39 in my dataset, but he was 40 when he missed against Espanyol on the final day of the 2021/22 season, effectively relegating Granada from La Liga.\nSimilarly, the dataset indicates a 17 year-old - Bojan Krkic. But he was 18 by the time he took his penalty for Barcelona against Manchester United in the Champions League. This is all rather annoying, but it would be more trouble than it‚Äôs worth to separate out every single penalty from each player‚Äôs season statistics and dial in the taker‚Äôs age on a specific date. It just means there is a +/- of 9 months (i.e.¬†the length of a season) for each player‚Äôs age."
  },
  {
    "objectID": "posts/no-fear-at-that-age/index.html#averages",
    "href": "posts/no-fear-at-that-age/index.html#averages",
    "title": "No Fear At That Age",
    "section": "Averages",
    "text": "Averages\nIn this analysis I calculate conversion rates in two different ways, which reflect slightly different questions:\n\nWeighted (overall) mean: This is the percentage of all penalties scored divided by the total penalties attempted within a group (e.g.¬†a competition). Every penalty counts equally, so players who take more penalties have more influence. This measure tells us the true success rate of the group as a whole.\nUnweighted (player) mean: This is the simple average of individual players‚Äô conversion rates. Each player counts equally, no matter how many penalties they have taken. This measure answers the question: what does the ‚Äúaverage player‚Äù in this group look like?\n\nIn the charts shown here, the main benchmark (red dashed line) is the weighted overall mean, because it reflects the actual outcome of all penalties taken across the dataset."
  },
  {
    "objectID": "posts/no-fear-at-that-age/index.html#analysis",
    "href": "posts/no-fear-at-that-age/index.html#analysis",
    "title": "No Fear At That Age",
    "section": "Analysis",
    "text": "Analysis\nFirst off, when it comes to conversion rates across the leagues, there are no differences whatsoever. Which is boring but convenient that we don‚Äôt need to worry too much about league effects.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPKatt\nPK\nPKm\nconversion_rate\n\n\nComp\n\n\n\n\n\n\n\n\nCL\n925\n714\n211\n77.189189\n\n\nEPL\n2892\n2280\n612\n78.838174\n\n\nLa Liga\n2956\n2288\n668\n77.401894\n\n\n\n\n\n\n\nOr do we? Any differences when we break the leagues down by age group?\nThere‚Äôs maybe a trend towards improved penalty conversion as you accumulate experience. The ‚Äòno fear‚Äô players are slightly more clinical than the players aged 21-23 who may be coming under pressure to make the next step as more mature and consistent players.\nBut this is the smallest dataset - only 925 penalties.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAge Group Penalty Data (Premier League)\n\n\n\n\n\n\n\n\n\nAge Group\nPenalty Attempts\nPenalty Conversions\nConversion Rate (%)\n\n\n\n\n&lt;=20: No Fear At That Age?\n80\n60\n75.00\n\n\n21-23: Not A Kid Anymore\n503\n398\n79.13\n\n\n24-26: Early Peak\n834\n654\n78.42\n\n\n27-29: Peak Peak\n793\n624\n78.69\n\n\n30-32: Over The Hill?\n495\n387\n78.18\n\n\n33+: Cherry On Top\n187\n157\n83.96\n\n\nGrand Total\n2892\n2280\n78.84\n\n\n\nIn the Premier League, things level out a bit more, although there still seems to be a mild advantage for experience.\n\n\nAge Group Penalty Data (La Liga)\n\n\n\n\n\n\n\n\n\nAge Group\nPenalty Attempts\nPenalty Conversions\nConversion Rate (%)\n\n\n\n\n&lt;=20: No Fear At That Age?\n81\n63\n77.78\n\n\n21-23: Not A Kid Anymore\n405\n307\n75.80\n\n\n24-26: Early Peak\n829\n653\n78.77\n\n\n27-29: Peak Peak\n833\n644\n77.31\n\n\n30-32: Over The Hill?\n511\n400\n78.28\n\n\n33+: Cherry On Top\n297\n221\n74.41\n\n\nGrand Total\n2956\n2288\n77.40\n\n\n\nThings get flipped on their head a little bit in La Liga. For the first time, the Cherry on Top vets aren‚Äôt the most effective penalty takers. In fact, in La Liga they are the worst. Meanwhile, the 20s and under are right up there near the top. And if we drill down into that age group, we can really appreciate how precocious those La Liga teens are.\n\n\n\n\n\n\n\n\n\nAge Group\nPenalty Attempts\nPenalty Conversions\nConversion Rate (%)\n\n\n\n\n&lt;=20: No Fear At That Age?\n81\n63\n77.78\n\n\n18\n10\n8\n80.00\n\n\n19\n27\n24\n88.89\n\n\n20\n44\n31\n70.45\n\n\n\nLet‚Äôs remove the 20 year olds. Now, La Liga teens have a success rate of 86%! Of course, there‚Äôs a caveat‚Ä¶ That‚Äôs a population size of just 37. Ezequiel Garay - one of history‚Äôs great centre-back penalty takers and a stalwart of my FC Atlas team in Football Manager - accounts for 22% of the entire La Liga teenage penalty taking population. And Jose Antonio Reyes accounts for another 19%. All together, those two players - and their combined 92% success rate - represent 41% of the whole group.\nSo let‚Äôs bundle everything together and see what we get‚Ä¶\n\n\n\n\n\n\n\n\n\nAge Group\nPenalty Attempts\nPenalty Conversions\nConversion Rate (%)\n\n\n\n\n&lt;=20: No Fear At That Age\n202\n153\n75.74\n\n\n21-23: Not A Kid Anymore\n1047\n804\n76.79\n\n\n24-26: Early Peak\n1901\n1491\n78.43\n\n\n27-29: Peak Peak\n1898\n1485\n78.24\n\n\n30-32: Over The Hill?\n1164\n909\n78.09\n\n\n33+: Cherry On Top\n561\n440\n78.43\n\n\nGrand Total\n6773\n5282\n77.99\n\n\n\nThere is a very mild indication that more experienced players do better than younger players. Considering the lowest success rates are 20 and under, and 21-23 are 2nd-lowest, there is some indication that young players are not totally fearless. I think this could be particularly noteworthy because, players who are designated penalty takers at such a young are rare and they are, in all likelihood, technically gifted. Therefore, is it a psychological vulnerability that causes their penalty-taking to dip a little compared to their older peers? And that maybe they aren‚Äôt so impervious to fear as pundits may casually claim?\nLet‚Äôs see if this stands up to statistical scrutiny.\n\n\nLogistic Regression\n\nMethod\nEach penalty in the dataset is tied to a player, season, and league. Since some players take penalties in multiple seasons (or even in multiple leagues), the raw data contained repeated rows for the same player. To avoid overweighting those players, we collapsed the dataset to one row per player √ó age group √ó league, summing up penalties scored and attempted within each cell. This way, every player contributes fairly to the analysis.\nI used a logistic regression model because the outcome of interest‚Äîscoring or missing a penalty‚Äîis binary. Logistic regression lets us model the probability of success while accounting for the number of attempts in each cell. We tested age group, league, and their interaction to see if any of them had an effect on conversion rates. Confidence intervals were estimated around the predicted probabilities to judge how much overlap there was between groups.\n\n\nResults\nTo test whether penalty conversion varies by age or by league, I fit a logistic regression with both predictors and their interaction. The likelihood-ratio tests showed no evidence that either factor‚Äîor their combination‚Äîimproves model fit (all p &gt; .4). In other words, neither age group nor league explains variation in conversion odds.\nPredicted probabilities were remarkably consistent across groups, generally hovering between 73% and 84%. For instance:\n\n‚â§20 years: 73‚Äì78% across leagues\n\n21‚Äì23 years: 71‚Äì79%\n\n27‚Äì29 years (peak): 77‚Äì79%\n\n33+ years: 74‚Äì84%\n\nConfidence intervals overlapped substantially, indicating no systematic age or league effect.\nNote: Bars show predicted conversion probabilities with 95% confidence intervals. The dashed line indicates the overall average (~78%).\n\n\n\n\n\n\nconversion by age\n\n\n\nage_group\nComp\npred_prob\nci_low\nci_high\n\n\n\n\n720\n&lt;=20: No Fear At That Age?\nCL\n0.731707\n0.577484\n0.844769\n\n\n721\n&lt;=20: No Fear At That Age?\nEPL\n0.750000\n0.643950\n0.832670\n\n\n452\n&lt;=20: No Fear At That Age?\nLa Liga\n0.777778\n0.674573\n0.855275\n\n\n309\n21-23: Not A Kid Anymore\nCL\n0.712230\n0.631588\n0.781332\n\n\n94\n21-23: Not A Kid Anymore\nEPL\n0.791252\n0.753518\n0.824555\n\n\n41\n21-23: Not A Kid Anymore\nLa Liga\n0.758025\n0.713916\n0.797264\n\n\n258\n24-26: Early Peak\nCL\n0.773109\n0.715574\n0.821903\n\n\n7\n24-26: Early Peak\nEPL\n0.784173\n0.754948\n0.810785\n\n\n26\n24-26: Early Peak\nLa Liga\n0.787696\n0.758529\n0.814203\n\n\n333\n27-29: Peak Peak\nCL\n0.797794\n0.745865\n0.841369\n\n\n10\n27-29: Peak Peak\nEPL\n0.786885\n0.756998\n0.814000\n\n\n83\n27-29: Peak Peak\nLa Liga\n0.773109\n0.743418\n0.800288\n\n\n498\n30-32: Over The Hill?\nCL\n0.772152\n0.700306\n0.830932\n\n\n517\n30-32: Over The Hill?\nEPL\n0.781818\n0.743263\n0.816017\n\n\n68\n30-32: Over The Hill?\nLa Liga\n0.782779\n0.744914\n0.816408\n\n\n807\n33+: Cherry On Top\nCL\n0.805195\n0.701640\n0.879006\n\n\n520\n33+: Cherry On Top\nEPL\n0.839572\n0.779802\n0.885500\n\n\n773\n33+: Cherry On Top\nLa Liga\n0.744108\n0.691427\n0.790519\n\n\n\n\n\n\n\n\n\n\nSources\n\nImage: ‰∏≠ÂõΩÊñ∞ÈóªÁ§æ, CC BY 3.0 https://creativecommons.org/licenses/by/3.0, via Wikimedia Commons\n\nData assembled from: Stathead"
  },
  {
    "objectID": "posts/scraper-fc-api-doc/index.html",
    "href": "posts/scraper-fc-api-doc/index.html",
    "title": "ScraperFC API Documentation",
    "section": "",
    "text": "Copyright 2022 Owen Seymour. Use of this source code is governed by the GPL 3.0 license."
  },
  {
    "objectID": "posts/scraper-fc-api-doc/index.html#scrape_stats",
    "href": "posts/scraper-fc-api-doc/index.html#scrape_stats",
    "title": "ScraperFC API Documentation",
    "section": "scrape_stats()",
    "text": "scrape_stats()\n\nClass: ScraperFC.fbref.FBref\nMethod: scrape_stats()\nReturns: A tuple of DataFrames\n\n\n\n\n\n\n\nUsage considerations\n\n\n\n\nBefore using this scraper on FBref data, review the Sports Reference Terms of Service.\n\nSection 5 of their Site Terms of Use\nSR and Data Use policy\nBot/Scraping/Crawler Traffic policies\n\nData usage: FBref permits scraping only under certain use cases (e.g., personal or educational). It is not permitted for competing analytics services or for public hosting.\nRate limiting: FBref requests no more than 10 site requests per minute. This scraper uses wait_time=7 to pause between requests. Always check the current terms of service before scraping.\n\n\n\nscrape_stats() allows you to download FBref season-level Squad Stats, Opponent Stats, and Player Stats for a chosen statistics collection such as ‚ÄúAdvanced Goalkeeping‚Äù.\nYou can reference the available statistics collections through this FBref navigation:\nCompetition &gt; ‚ÄòSquad & Player Stats‚Äô dropdown &gt; Statistical Collection &gt; Toggle between ‚ÄòSquad & Opponent Stats‚Äô or scroll for ‚ÄòPlayer Stats‚Äô\nYou can find an example of Premier League 2024/25 ‚ÄòPlayer Stats‚Äô from the ‚ÄòStandard‚Äô stats collection here."
  },
  {
    "objectID": "posts/scraper-fc-api-doc/index.html#prerequisites",
    "href": "posts/scraper-fc-api-doc/index.html#prerequisites",
    "title": "ScraperFC API Documentation",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nInstall the ScraperFC package:\n\npip install ScraperFC\n(The package is not currently available on conda or conda-forge.)\n\nLoad the fbref module:\n\nfrom ScraperFC.fbref import FBref\n\nInitialize the scraper object:\n\nfb_scraper = FBref()"
  },
  {
    "objectID": "posts/scraper-fc-api-doc/index.html#parameters",
    "href": "posts/scraper-fc-api-doc/index.html#parameters",
    "title": "ScraperFC API Documentation",
    "section": "Parameters",
    "text": "Parameters\n\nyear (str, required)\n\nSeason to scrape.\nFormat: match the season strings on the Competition History page of the target league (e.g., Big 5 Leagues).\nYou can check accepted year inputs with get_valid_seasons():\n\n\nvalid_seasons = fb_scraper.get_valid_seasons(\"La Liga\")\nseason_list = list(valid_seasons.keys())\nprint(season_list)\n\n\n\n\n\n\nOutput\n\n\n\n['2025-2026', '2024-2025', '2023-2024', '2022-2023', ...]\n\n\n\nleague (str, required)\n\nLeague to scrape (usually the long name, e.g., ‚ÄúBundesliga‚Äù, ‚ÄúLigue 1‚Äù; some exceptions like ‚ÄúEPL‚Äù).\nCheck accepted values with comps.keys():\n\n\nvalid_league_names = list(fb_scraper.comps.keys())\nprint(valid_league_names)\n\n\n\n\n\n\nOutput\n\n\n\n['Copa Libertadores', 'Champions League', 'Europa League', ...]\n\n\n\nstat_category (str, required)\n\nStat category to scrape; use the full names except ‚Äúmiscellaneous‚Äù, which should be \"misc\".\nCheck accepted values with stats_categories.keys():\n\n\nstat_categories = list(fb_scraper.stats_categories.keys())\nprint(stat_categories)\n\n\n\n\n\n\nOutput\n\n\n\n['standard', 'goalkeeping', 'advanced goalkeeping', ...]"
  },
  {
    "objectID": "posts/scraper-fc-api-doc/index.html#returns",
    "href": "posts/scraper-fc-api-doc/index.html#returns",
    "title": "ScraperFC API Documentation",
    "section": "Returns",
    "text": "Returns\nA tuple of three pd.DataFrame objects: (squad_stats, opponent_stats, player_stats)\n\nsquad_stats: Aggregated stats for all squads in the league and season.\nopponent_stats: Aggregated opponent stats for all squads.\nplayer_stats: Player-level stats for the league and season."
  },
  {
    "objectID": "posts/scraper-fc-api-doc/index.html#error-handling",
    "href": "posts/scraper-fc-api-doc/index.html#error-handling",
    "title": "ScraperFC API Documentation",
    "section": "Error handling",
    "text": "Error handling\nIf an invalid league name is passed, an error message will print the accepted entries:\nseasons = [\"2025-2026\"]\nleagues = [\"not a league\"]\n\n\n\n\n\n\nOutput\n\n\n\nScraping not a league 2025-2026...\nFailed scraping not a league 2025-2026: not a league is not a valid league for FBref. Valid leagues are ['Copa Libertadores', 'Champions League', 'Europa League', 'Europa Conference League', ...]"
  },
  {
    "objectID": "posts/scraper-fc-api-doc/index.html#full-workflow-example",
    "href": "posts/scraper-fc-api-doc/index.html#full-workflow-example",
    "title": "ScraperFC API Documentation",
    "section": "Full workflow example",
    "text": "Full workflow example\nThis example loops through multiple leagues and seasons, retrieves the standard and misc stat categories, and stores only the player_stats DataFrames.\nfrom ScraperFC.fbref import FBref\nimport pandas as pd\n\n# Initialize scraper object\nfb_scraper = FBref()\n\n# Select desired seasons and leagues\nseasons = [\"2022-2023\", \"2023-2024\"]\nleagues = [\"EPL\", \"La Liga\"]\n\n# Capture the DataFrames during the loop\nall_player_dfs = []\n\n# Loop through all desired seasons and leagues\nfor season in seasons:\n    for league in leagues:\n        try:\n            print(f\"Scraping {league} {season}...\")\n\n            # Scrape 'standard' stats and omit squad/opponent stats\n            _, _, df_standard = fb_scraper.scrape_stats(season, league, \"standard\")\n\n            # Scrape 'misc' stats and omit squad/opponent stats\n            _, _, df_misc = fb_scraper.scrape_stats(season, league, \"misc\")\n\n            # Populate the list\n            all_player_dfs.append(df_standard)\n            all_player_dfs.append(df_misc)\n        except Exception as e:\n            print(f\"Failed scraping {league} {season}: {e}\")\n\nprint(\"Scraping complete.\")"
  },
  {
    "objectID": "posts/scraper-fc-api-doc/index.html#versioning",
    "href": "posts/scraper-fc-api-doc/index.html#versioning",
    "title": "ScraperFC API Documentation",
    "section": "Versioning",
    "text": "Versioning\nThis documentation applies to ScraperFC v3.4.0 (current stable release).\nTo check your installed version:\nfrom importlib.metadata import version\n\ninstalled_version = version(\"ScraperFC\")\nprint(f\"ScraperFC Version: {installed_version}\")\n\n\n\n\n\n\nWarning\n\n\n\nA major overhaul to the league-names parameter is planned for v4.0. Upgrading may break existing code. To preview upcoming changes, switch the documentation dropdown (bottom-right) from ‚Äústable‚Äù to ‚Äúlatest‚Äù."
  },
  {
    "objectID": "posts/scraper-fc-api-doc/index.html#sources",
    "href": "posts/scraper-fc-api-doc/index.html#sources",
    "title": "ScraperFC API Documentation",
    "section": "Sources",
    "text": "Sources\n\nScraperFC‚Äôs official docs\nPackage page on PyPi\nCreator‚Äôs GitHub\nCreator‚Äôs Buy Me a Coffee"
  },
  {
    "objectID": "posts/too-messy-to-melt/index.html",
    "href": "posts/too-messy-to-melt/index.html",
    "title": "Too Messy to Melt",
    "section": "",
    "text": "In pandas (and tidy-data workflows), melt() is the standard tool for reshaping a wide table into a long one.\nIn this project, the original spreadsheet (see below) wasn‚Äôt just wide ‚Äî it was inconsistent across season formats, team naming conventions, and placeholder values (e.g., COVID). A naive pd.melt() would have produced incorrect joins and silent errors.\n\n\n\nUnusably messy attendance spreadsheet\n\n\nThis page documents the reproducible reshaping pipeline used to build the final open dataset.\nThe final output of this process is the perfect_tidy_data.csv file. Read on to learn more about its structure, contents and composition or simply Download perfect_tidy_data.csv. The CSV becomes an analysis-ready Python DataFrame after some further enrichment - see the final code block for details."
  },
  {
    "objectID": "posts/too-messy-to-melt/index.html#introduction",
    "href": "posts/too-messy-to-melt/index.html#introduction",
    "title": "Too Messy to Melt",
    "section": "",
    "text": "In pandas (and tidy-data workflows), melt() is the standard tool for reshaping a wide table into a long one.\nIn this project, the original spreadsheet (see below) wasn‚Äôt just wide ‚Äî it was inconsistent across season formats, team naming conventions, and placeholder values (e.g., COVID). A naive pd.melt() would have produced incorrect joins and silent errors.\n\n\n\nUnusably messy attendance spreadsheet\n\n\nThis page documents the reproducible reshaping pipeline used to build the final open dataset.\nThe final output of this process is the perfect_tidy_data.csv file. Read on to learn more about its structure, contents and composition or simply Download perfect_tidy_data.csv. The CSV becomes an analysis-ready Python DataFrame after some further enrichment - see the final code block for details."
  },
  {
    "objectID": "posts/too-messy-to-melt/index.html#dataset-scope",
    "href": "posts/too-messy-to-melt/index.html#dataset-scope",
    "title": "Too Messy to Melt",
    "section": "Dataset Scope",
    "text": "Dataset Scope\nAll Premier League relegations with usable attendance data. This means Covid seasons are excluded. Each Premier League relegation event is represented across a consistent four-season window and includes league performance as well as attendance figures. Data is on a per-season basis, not per-match. - Year -1: Season before relegation\n- Year 0: Relegation season (Premier League)\n- Year +1: First post-relegation season\n- Year +2: Second post-relegation season\nA temporary Year +3 is generated programmatically only to determine the Year +2 season outcome (Promoted / Survived / Relegated). After outcome extraction, the Year +3 rows are dropped.\nGranularity is one row per team √ó season √ó relegation event. So one relegation event (e.g., Burnley 2023-24) is represented by four rows (Year -1 through Year +2)."
  },
  {
    "objectID": "posts/too-messy-to-melt/index.html#data-sources",
    "href": "posts/too-messy-to-melt/index.html#data-sources",
    "title": "Too Messy to Melt",
    "section": "Data sources",
    "text": "Data sources\n\nAttendance data\nAttendance values were manually compiled into an Excel workbook using:\n\nEuropean-Football-Statistics.co.uk (season-level attendances)\n\nBecause COVID-affected seasons are not comparable to normal seasons, I sometimes entered the string value COVID into attendance cells during manual compilation. The pipeline converts these placeholders to missing values (pd.NA) before numeric conversion.\nDownload Relegation Attendance Churn.xlsx\n\n\nLeague position and performance\nLeague tier, final position, and raw season performance totals come from:\n\nThe Fjelstul English Football Database (standings dataset)\nFjelstul, Joshua C. ‚ÄúThe Fjelstul English Football Database v1.1.0.‚Äù May 26, 2024. https://www.github.com/jfjelstul/englishfootball\n\n\nLicensing note: The Fjelstul database is distributed under CC-BY-SA 4.0. This derived dataset is made available under the same CC BY-SA 4.0 license.\n\n\nPatch file\nThe Fjelstul dataset does not include the 2024/25 season, so I have supplemented it with a patch file (standings24_25.csv) to include the most recent completed season.\n\nDownload standings24_25.csv"
  },
  {
    "objectID": "posts/too-messy-to-melt/index.html#data-dictionary",
    "href": "posts/too-messy-to-melt/index.html#data-dictionary",
    "title": "Too Messy to Melt",
    "section": "Data dictionary",
    "text": "Data dictionary\n\nIdentifiers and structure\n\n\n\n\n\n\n\n\nColumn\nType\nDescription\n\n\n\n\nRelegation_Event_ID\nstring\nUnique ID for a relegation event (\"{Team} {Season}\")\n\n\nTeam\nstring\nStandardized club name (matches standings naming)\n\n\nSeason\nstring\nSeason in YYYY-YY format (e.g., 2002-03)\n\n\nYear_vs_Relegation\nint\nRelative season index: -1, 0, 1, 2\n\n\n\n\n\nAttendance\n\n\n\n\n\n\n\n\nColumn\nType\nDescription\n\n\n\n\nAttendance\nint (nullable)\nAverage home league attendance. Missing where unusable (e.g.¬†COVID).\n\n\n\n\n\nLeague status and outcome\n\n\n\n\n\n\n\n\nColumn\nType\nDescription\n\n\n\n\nTier\nint (nullable)\nLeague tier (1 = top flight, 2 = Championship, etc.)\n\n\nPosition\nint (nullable)\nFinal league position\n\n\nYear_End_Outcome\nstring\nPromoted, Survived, or Relegated\n\n\n\n\n\nRaw season performance totals\n\n\n\nColumn\nType\nDescription\n\n\n\n\nGames_Played_History\nint (nullable)\nLeague matches played\n\n\nWins_History\nint (nullable)\nLeague wins\n\n\nGoals_For_History\nint (nullable)\nLeague goals scored\n\n\nGoals_Against_History\nint (nullable)\nLeague goals conceded\n\n\nPoints_History\nint (nullable)\nLeague points total"
  },
  {
    "objectID": "posts/too-messy-to-melt/index.html#inputs-and-outputs",
    "href": "posts/too-messy-to-melt/index.html#inputs-and-outputs",
    "title": "Too Messy to Melt",
    "section": "Inputs and outputs",
    "text": "Inputs and outputs\n\nInputsOutputs\n\n\n\n\n\nFile\nPurpose\n\n\n\n\nRelegation Attendance Churn.xlsx\nWide-format attendance sheet\n\n\nStandings24_25.csv\nPatch file for 24/25 season\n\n\n\n\n\n\n\n\nFile\nPurpose\n\n\n\n\nperfect_tidy_data.csv\nFinal tidy dataset"
  },
  {
    "objectID": "posts/too-messy-to-melt/index.html#dataset-design",
    "href": "posts/too-messy-to-melt/index.html#dataset-design",
    "title": "Too Messy to Melt",
    "section": "Dataset design",
    "text": "Dataset design\n\nPrimary identifier: Relegation_Event_ID\nA relegation event is uniquely identified as:\nRelegation_Event_ID = \"{Team} {RelegationSeason}\"\nExample: Burnley 2023-24\nThis identifier is repeated across the four rows representing Year -1 through Year +2."
  },
  {
    "objectID": "posts/too-messy-to-melt/index.html#reshaping-pipeline",
    "href": "posts/too-messy-to-melt/index.html#reshaping-pipeline",
    "title": "Too Messy to Melt",
    "section": "Reshaping pipeline",
    "text": "Reshaping pipeline\n\nStep 0: Prerequisites\nimport pandas as pd\nimport numpy as np\n# You may need to install thefuzz\npip install thefuzz\nfrom thefuzz import process\n\n\nStep 1 ‚Äî Load the wide spreadsheet and clean attendance columns\nWhy: The attendance sheet is wide-format, and attendance values include commas and placeholders (e.g., COVID).\nWhat happens: - Strip commas (e.g., 23,721 ‚Üí 23721) - Convert COVID and nan placeholders to missing values (pd.NA) - Coerce to numeric\nattendance_cols = [c for c in df_wide.columns if \"Attendance\" in c]\nfor col in attendance_cols:\n    df_wide[col] = df_wide[col].astype(str).str.replace(',', '').replace('COVID', pd.NA).replace('nan', pd.NA)\n    df_wide[col] = pd.to_numeric(df_wide[col], errors='coerce')\n\n\nStep 2 ‚Äî Load standings data (for auditing + enrichment)\nWhy: Team naming mismatches and season key mismatches can silently break merges. The standings dataset provides a stable reference list of teams and seasons.\nWhat happens: - Load standings.csv - Optionally append standings24_25.csv - Rename and select relevant columns - Coerce numeric columns\ntry:\n    # Load 'season' as string to be safe\n    df_history = pd.read_csv('../../assets/files/datasets/standings.csv', dtype={'season': str})\n\n    # --- Load patch file and combine ---\n    try:\n        df_patch = pd.read_csv('../../assets/files/datasets/standings24_25.csv', dtype={'season': str})\n        # Append patch data to history data\n        df_history = pd.concat([df_history, df_patch], ignore_index=True)\n        print(\"Step 2a: Loaded and applied 'standings24_25.csv'.\")\n    except FileNotFoundError:\n        print(\"Step 2a: 'standings24_25.csv' not found. Skipping patch.\")\n    # --- End new patch logic ---\n\n    print(\"Step 2b: Loaded historical data for auditing.\")\n\n    # Create the cleaned df_positions here for later use\n    df_positions = df_history.rename(columns={\n        'team_name': 'Team',\n        'season': 'Season',\n        'position': 'Position_History',\n        'played': 'Games_Played_History',\n        'wins': 'Wins_History',\n        'goals_for': 'Goals_For_History',\n        'goals_against': 'Goals_Against_History',\n        'points': 'Points_History',\n        'tier': 'Tier_History'\n    })[['Team', 'Season', 'Position_History', 'Games_Played_History', 'Wins_History',\n        'Goals_For_History', 'Goals_Against_History', 'Points_History', 'Tier_History']]\n\n    # Convert new history columns to numeric\n    numeric_cols = ['Position_History', 'Games_Played_History', 'Wins_History',\n                    'Goals_For_History', 'Goals_Against_History', 'Points_History', 'Tier_History']\n    for col in numeric_cols:\n        df_positions[col] = pd.to_numeric(df_positions[col], errors='coerce')\n\n\nStep 3 ‚Äî Audit team names (fuzzy matching)\nWhy: The manual spreadsheet uses informal names (Man City, Spurs, etc.). The merge requires standardized names.\nWhat happens:\n- Identify team names in attendance sheet that don‚Äôt match standings - Propose high-confidence fuzzy matches (&gt;85) - Warn on low-confidence values\nteams_in_wide_df = set(df_wide['Relegated Team'].astype(str).unique())\n    teams_in_history_df = set(df_positions['Team'].astype(str).unique())\n\n    unmatched_teams = teams_in_wide_df.difference(teams_in_history_df)\n\n    # Create an empty map to build automatically\n    auto_team_name_map = {}\n\n    if unmatched_teams:\n        print(\"--- AUDIT: TEAM NAME MISMATCHES FOUND ---\")\n        print(\"The following teams from your file do not match the history file.\")\n        print(\"Attempting to build an automatic mapping...\")\n\n        # Loop through each unique unmatched team and find the best match\n        for team in sorted(unmatched_teams):\n            # process.extractOne returns a tuple: (best_match, score)\n            suggestion = process.extractOne(team, teams_in_history_df)\n\n            # Auto-map spaces, asterisks, and high-confidence matches\n            if suggestion[1] &gt; 85:\n                print(f\"  - Auto-mapping: \\\"{team}\\\" -&gt; \\\"{suggestion[0]}\\\" (Score: {suggestion[1]})\")\n                auto_team_name_map[team] = suggestion[0]\n            else:\n                # Don't map low-confidence or junk data\n                if team not in ['nan', 'TEAM', 'Relegated Team']:\n                    print(\n                        f\"  - WARNING: \\\"{team}\\\" has no confident match. (Best: \\\"{suggestion[0]}\\\" at {suggestion[1]}%)\")\n                    print(f\"    -&gt; Please add a fix for \\\"{team}\\\" to 'manual_overrides_map' in Step 4.\")\n\n        print(\"---------------------------------------------\")\n    else:\n        print(\"--- AUDIT: TEAM NAMES OK ---\")\n        print(\"All team names in your file match the history file.\")\n\nexcept FileNotFoundError:\n    print(\"Error: '../../assets/files/datasets/standings.csv' not found. Skipping audit and enrichment.\")\n    # Create empty dataframes if file not found\n    df_positions = pd.DataFrame(columns=['Team', 'Season', 'Position_History', 'Games_Played_History',\n                                         'Wins_History', 'Goals_For_History', 'Goals_Against_History',\n                                         'Points_History', 'Tier_History'])\n    auto_team_name_map = {}\n\n\nStep 4 ‚Äî Standardize team names (auto-map + manual overrides)\nWhy: Fuzzy matching is helpful but not perfect; known edge cases are fixed with manual overrides.\nWhat happens: - Merge the auto-map and manual overrides\n- Replace names in the wide spreadsheet\n- Filter out remaining junk/unmapped rows\nmanual_overrides_map = {\n    \"Man Utd\": \"Manchester United\",\n    \"Man City\": \"Manchester City\",\n    \"Spurs\": \"Tottenham Hotspur\",\n    \"QPR\": \"Queens Park Rangers\",\n    \"Wolves\": \"Wolverhampton Wanderers\",\n    \"Sheff Utd\": \"Sheffield United\",\n    \"Sheff Wed\": \"Sheffield Wednesday\",\n    \"Nott'm Forest\": \"Nottingham Forest\",\n    \"Notts County\": \"Nottingham Forest\"\n    # e.g., if audit warns about \"Bradford\", add:\n    # \"Bradford\": \"Bradford City\",\n}\n# Combine the auto-generated map with the manual overrides\n# This is where we combine the two dictionaries.\n# The 'manual_overrides_map' will overwrite any conflicting keys from 'auto_team_name_map'.\nfinal_team_map = {**auto_team_name_map, **manual_overrides_map}\n\ndf_wide['Relegated Team'] = df_wide['Relegated Team'].replace(final_team_map)\nprint(\"Step 4: Standardized 'Relegated Team' names using auto-mapping and manual overrides.\")\n# --- 4.5. FILTERING STEP ---\n# Now that names are mapped, we can filter out junk rows that didn't get mapped\nteams_in_history_df = set(df_positions['Team'].astype(str).unique())\ndf_wide = df_wide[df_wide['Relegated Team'].isin(teams_in_history_df)]\nprint(\"Step 4.5: Filtered out junk rows (e.g., 'nan', 'TEAM').\")\n\n\nStep 5 ‚Äî Create a stable event key (Relegation_Event_ID)\nWhy: Each relegation event needs a stable identifier across Year -1..+2.\ndf_wide['Relegation_Event_ID'] = df_wide['Relegated Team'] + ' ' + df_wide['Season']\nprint(\"Step 5: Created 'Relegation_Event_ID'.\")\n\n\nStep 6 ‚Äî Convert wide ‚Üí tidy (safe slices + concat)\nWhy: The attendance sheet is wide and not safely meltable without careful column mapping.\nWhat happens:\n- Create four normalized slices (Year -1..+2)\n- Concatenate into one long table with a consistent schema\n## Helper function to create each slice\ndef make_slice(df, team_col, season_col, att_col, year_vs):\n    # --- Check if att_col exists, otherwise use pd.NA ---\n    # This makes the function robust for the missing Y3 attendance\n    if att_col not in df.columns:\n        # Create a temporary column of NAs if the attendance col doesn't exist\n        df = df.assign(Attendance_tmp=pd.NA) \n    else:\n        # If the col *does* exist, rename it\n        df = df.rename(columns={att_col: \"Attendance_tmp\"})\n        \n    slice_df = df.rename(columns={\n        team_col: \"Team\",\n        season_col: \"Season_tmp\"\n    }).assign(Year_vs_Relegation=year_vs)\n\n    # Select and rename final columns\n    slice_df = slice_df[['Relegation_Event_ID', 'Team', 'Season_tmp', 'Attendance_tmp', 'Year_vs_Relegation']].copy()\n    slice_df.columns = ['Relegation_Event_ID', 'Team', 'Season', 'Attendance', 'Year_vs_Relegation']\n\n    return slice_df\n\n# Create slices (Only up to Year 2)\nslice_minus1 = make_slice(df_wide, \"Relegated Team\", \"Year Before\", \"Year Before Att\", -1)\nslice_0      = make_slice(df_wide, \"Relegated Team\", \"Season\", \"Attendance\", 0)\nslice_1      = make_slice(df_wide, \"Relegated Team\", \"Year After\", \"Attendance year after\", 1)\nslice_2      = make_slice(df_wide, \"Relegated Team\", \"2 years after\", \"Attendance 2 years after\", 2)\n\n# Concatenate slices safely\ndf_tidy = pd.concat([slice_minus1, slice_0, slice_1, slice_2], ignore_index=True)\n\nprint(\"Step 6: Data has been 'tidied' successfully!\")\n\n\nStep 7 ‚Äî Standardize season keys (YYYY-YY)\n\nWhy: Season formats vary (e.g., 1991-1992 vs 1992-93) and must align for joins.\n\n# --- HELPER FUNCTION 1 ---\ndef format_season(season_str):\n    \"\"\"Converts '1991-1992' to '1991-92' and leaves '1992-93' as is.\"\"\"\n    if pd.isna(season_str):\n        return pd.NA\n    parts = str(season_str).split('-')\n    if len(parts) == 2:\n        if len(parts[1]) == 4:  # Format is '1991-1992'\n            return f\"{parts[0]}-{parts[1][-2:]}\"\n        else:  # Format is '1992-93'\n            return season_str\n    return season_str  # Return as-is if not in expected format\n\n# --- HELPER FUNCTION 2 ---\ndef increment_season(season_str):\n    \"\"\"Converts a season string like '1995-96' to '1996-97'.\"\"\"\n    if pd.isna(season_str):\n        return pd.NA\n    try:\n        start_year = int(season_str.split('-')[0])\n        next_start_year = start_year + 1\n        \n        # Handle the '1999-00' case\n        if next_start_year == 1999:\n            return \"1999-00\"\n        \n        next_end_year_short = str(next_start_year + 1)[-2:] # e.g., 97\n        return f\"{next_start_year}-{next_end_year_short}\"\n    except Exception as e:\n        print(f\"Error incrementing season '{season_str}': {e}\")\n        return pd.NA\n\n# Apply the formatting\ndf_tidy['Season'] = df_tidy['Season'].apply(format_season)\nprint(\"Step 7: Standardized 'Season' key to 'YYYY-YY' format (e.g., '1992-93').\")\n\n\nStep 7.5 ‚Äî Temporary Year +3 rows (outcome extraction only)\nWhy: To compute the outcome of Year +2, we need to observe the next season‚Äôs tier transition.\nprint(\"Step 7.5: Generating temporary Year 3 rows for outcome calculation...\")\n\n# 1. Find all Year 2 rows\ndf_y2_rows = df_tidy[df_tidy['Year_vs_Relegation'] == 2].copy()\n\n# 2. Transform them into Year 3 rows\ndf_y2_rows['Year_vs_Relegation'] = 3\ndf_y2_rows['Attendance'] = pd.NA # Attendance data is not needed\ndf_y2_rows['Season'] = df_y2_rows['Season'].apply(increment_season)\n\n# 3. Concatenate these helper rows back onto the main tidy dataframe\ndf_tidy = pd.concat([df_tidy, df_y2_rows], ignore_index=True)\nprint(\"Step 7.5: Temporary Year 3 rows created and added.\")\n\n\nStep 8 ‚Äî Enrich tidy data with standings (raw totals)\nWhy: Add tier, position, and season totals for later analysis while keeping this dataset ‚Äúraw‚Äù.\nif not df_positions.empty:\n    # --- Upgrade the history file's 'Season' column ---\n    season_numeric = pd.to_numeric(df_positions['Season'], errors='coerce').dropna()\n    season_end_year = (season_numeric + 1).astype(int).astype(str).str.zfill(4).str[-2:]\n    df_positions.loc[season_numeric.index, 'Season'] = season_numeric.astype(int).astype(str) + '-' + season_end_year\n    print(\"Step 8a: Upgraded history file 'Season' key.\")\n\n    # --- MODIFICATION ---\n    # We are NO LONGER calculating per-game metrics here.\n    # We are ONLY merging the raw values.\n    df_positions_merge = df_positions[[\n        'Team', 'Season', 'Position_History', 'Tier_History',\n        'Games_Played_History', 'Wins_History', 'Goals_For_History', \n        'Goals_Against_History', 'Points_History'\n    ]]\n    # --- END MODIFICATION ---\n\n    # --- Merge the data ---\n    print(\"Step 8b: Merging tidy data with position data...\")\n    df_final = pd.merge(\n        df_tidy,\n        df_positions_merge,  # Use the merge-ready dataframe with raw columns\n        on=['Team', 'Season'],\n        how='left'\n    )\n    df_final['Position'] = df_final['Position_History']\n    df_final['Tier'] = df_final['Tier_History']\n    print(\"Step 8: Data enriched. 'df_final' created and 'Tier' column added.\")\n\nelse:\n    print(\"Step 8: Skipping merge as 'standings.csv' was not loaded.\")\n    df_final = df_tidy.copy() \n    # Add empty columns\n    for col in ['Position', 'Tier', 'Games_Played_History', 'Wins_History', 'Goals_For_History', 'Goals_Against_History', 'Points_History']:\n        df_final[col] = pd.NA\n\n\nStep 8.5 ‚Äî Compute Year_End_Outcome from tier transitions\nWhy: Outcomes (Promoted/Survived/Relegated) are derived from how tier changes year-to-year within each event.\nprint(\"Step 8.5: Calculating 'Year_End_Outcome' based on precise timeline...\")\n\n# 1. Calculate the Tier Change (Tier_Next_Year - Tier_Current_Year)\ndf_final['Tier_Next_Year'] = df_final.groupby('Relegation_Event_ID')['Tier'].shift(-1)\ndf_final['Tier_Change'] = df_final['Tier_Next_Year'] - df_final['Tier']\n\n# 2. Map the Tier Change to the Outcome Label\ndef map_tier_change_to_outcome(row):\n    \"\"\"Maps the outcome based on the user's exact timeline definition.\"\"\"\n    \n    year_vs_relegation = row['Year_vs_Relegation'] \n    current_tier = row['Tier']\n    tier_change = row['Tier_Change']\n\n    # --- 1. Handle Year -1 (Based on CURRENT Tier) ---\n    if year_vs_relegation == -1:\n        if current_tier == 1:\n            return 'Survived'\n        if current_tier == 2:\n            return 'Promoted'\n        return pd.NA\n\n    # --- 2. Handle Year 0 (The Relegation Event) ---\n    if year_vs_relegation == 0:\n        return 'Relegated'\n\n    # --- 3. Handle Year +1 and +2 (Based on TIER CHANGE) ---\n    if year_vs_relegation in [1, 2]:\n        if pd.isna(tier_change):\n            return pd.NA \n        \n        if tier_change == -1:\n            return 'Promoted'\n        if tier_change == 0:\n            return 'Survived'\n        if tier_change == 1:\n            return 'Relegated'\n        \n        return pd.NA\n\n    return pd.NA # Catches Y3 row\n\n# Apply the function\ndf_final['Year_End_Outcome'] = df_final.apply(map_tier_change_to_outcome, axis=1)\nprint(\"Step 8.5: 'Year_End_Outcome' column successfully created.\")\n\n\nStep 9 ‚Äî Finalize schema and export\nWhat happens:\n- Cast numeric fields to nullable integers\n- Drop helper Year +3 rows\n- Select final column set and sort\n- Write perfect_tidy_data.csv\nprint(\"Step 9: Polishing final data...\")\n\n# --- MODIFICATION: Added all _History columns ---\nfinal_columns = [\n    'Relegation_Event_ID', 'Team', 'Season', 'Tier',\n    'Position', 'Attendance', 'Year_vs_Relegation', 'Year_End_Outcome',\n    'Games_Played_History', 'Wins_History', 'Goals_For_History', \n    'Goals_Against_History', 'Points_History'\n]\n# --- END MODIFICATION ---\n\n# Ensure final columns exist before slicing\nfor col in final_columns:\n    if col not in df_final.columns:\n        df_final[col] = pd.NA\n\n# --- MODIFICATION: Cast all numeric columns to Int64 ---\nfor col in ['Attendance', 'Position', 'Tier', 'Games_Played_History', 'Wins_History', 'Goals_For_History', 'Goals_Against_History', 'Points_History']:\n    df_final[col] = pd.to_numeric(df_final[col], errors='coerce').astype('Int64')\n# --- END MODIFICATION ---\n\n# --- DROP THE HELPER ROW ---\ndf_final = df_final[df_final['Year_vs_Relegation'] != 3].copy()\n\n# Keep only the final columns and sort\ndf_final = df_final[final_columns].sort_values(by=['Relegation_Event_ID', 'Year_vs_Relegation'])\n\n# Save the final, perfect data to a new CSV in the 'datasets' folder\noutput_path = \"../../assets/files/datasets/perfect_tidy_data.csv\"\ndf_final.to_csv(output_path, index=False)\nimport os\nprint(f\"Step 9: Success! Final table saved to '{output_path}'\")\n#| output: false"
  },
  {
    "objectID": "posts/too-messy-to-melt/index.html#from-tidy-data-to-analysis-ready-tables",
    "href": "posts/too-messy-to-melt/index.html#from-tidy-data-to-analysis-ready-tables",
    "title": "Too Messy to Melt",
    "section": "From tidy data to analysis-ready tables",
    "text": "From tidy data to analysis-ready tables\nWhile that completes the reshaping pipeline, further steps are needed to prepare the data for analysis and visualization.\nprint(\"--- PREPARING DATA FOR ANALYSIS ---\")\n# --- ANALYSIS PREP ---\n# This block creates the 'df_plot' DataFrame for all visualizations\n# 1. Get the baseline attendance (Year 0) for each event\ndf_y0_baseline = df_final[\n    df_final['Year_vs_Relegation'] == 0\n][['Relegation_Event_ID', 'Attendance']].rename(columns={'Attendance': 'Attendance_Y0_Baseline'})\n\n# 2. Merge this baseline back onto the main df\ndf_plot = pd.merge(df_final, df_y0_baseline, on='Relegation_Event_ID', how='left')\n\n# 3. Calculate the Pct Change vs. Year 0 for all years\ndf_plot['Pct_Change_vs_Y0'] = (\n    (df_plot['Attendance'] - df_plot['Attendance_Y0_Baseline']) / \n    df_plot['Attendance_Y0_Baseline']\n)\n\n# 4. Get the *key outcome* from Year 1 (the first post-relegation season)\ndf_y1_outcome = df_final[\n    df_final['Year_vs_Relegation'] == 1\n][['Relegation_Event_ID', 'Year_End_Outcome']].rename(columns={'Year_End_Outcome': 'Outcome_Group'})\n\n# 5. Merge this outcome group onto the whole plot dataset\ndf_plot = pd.merge(df_plot, df_y1_outcome, on='Relegation_Event_ID', how='left')\n\n\n# 5.5: IMPUTE 2024-25 OUTCOMES ---\n# The Y+1 outcome for the 2023-24 cohort is NA. We impute it manually.\nprint(\"Imputing outcomes for 2023-24 cohort...\")\n\n# Define our imputations based on likely 2024-25 season-end performance\nimpute_map = {\n    'Burnley 2023-24': 'Promoted',\n    'Sheffield United 2023-24': 'Survived', # Assuming playoffs = Survived\n    'Luton Town 2023-24': 'Relegated'\n}\n\n# Apply the imputation\n# This finds rows where Outcome_Group is NA and maps the Event ID to our new value\ndf_plot['Outcome_Group'] = df_plot['Outcome_Group'].fillna(\n    df_plot['Relegation_Event_ID'].map(impute_map)\n)\nprint(\"Imputation complete.\")\n\n# 6. Convert Pct_Change to a percentage number (e.g., 0.05 -&gt; 5)\ndf_plot['Pct_Change_vs_Y0_Display'] = df_plot['Pct_Change_vs_Y0'] * 100\n\n# 7. Calculate Per-Game metrics on the fly\ndf_plot['Goals_For_Per_Game'] = df_plot['Goals_For_History'] / df_plot['Games_Played_History']\ndf_plot['Points_Per_Game'] = df_plot['Points_History'] / df_plot['Games_Played_History']\n\n# 8. Define the FINAL anomaly list\n# We are KEEPING Wimbledon, as it's a valid case study.\nanomaly_events = [\n    'Middlesbrough 1992-93', # Rebuild\n    'Sunderland 1996-97',    # New stadium\n    'Leicester City 2001-02', # New stadium\n    'Bolton Wanderers 1995-96'  # New stadium (in Y+2)\n]\n\n# 9. Create the FINAL filtered DataFrame for plotting\ndf_plot_filtered = df_plot[~df_plot['Relegation_Event_ID'].isin(anomaly_events)]\nprint(f\"Removed {len(df_plot) - len(df_plot_filtered)} total data points for structural anomalies.\")\n\n# 10. Create the cleaner plot labels\nlabel_map = {\n    'Promoted': 'Promoted (Back in PL)',\n    'Survived': 'Survived (Still in Champ)',\n    'Relegated': 'Relegated (Down to L1)'\n}\ndf_plot['Plot_Group_Label'] = df_plot['Outcome_Group'].map(label_map)\ndf_plot_filtered['Plot_Group_Label'] = df_plot_filtered['Outcome_Group'].map(label_map)\n\nprint(\"--- Analysis data is ready. ---\")"
  },
  {
    "objectID": "posts/too-messy-to-melt/index.html#analysis-prep-script-full-copy-paste-ready",
    "href": "posts/too-messy-to-melt/index.html#analysis-prep-script-full-copy-paste-ready",
    "title": "Too Messy to Melt",
    "section": "Analysis prep script (full, copy-paste ready)",
    "text": "Analysis prep script (full, copy-paste ready)\n## From tidy data to analysis-ready tables\nprint(\"--- PREPARING DATA FOR ANALYSIS ---\")\n\n# --- ANALYSIS PREP ---\n# This block creates the 'df_plot' DataFrame for all visualizations\n# 1. Get the baseline attendance (Year 0) for each event\ndf_y0_baseline = df_final[\n    df_final['Year_vs_Relegation'] == 0\n][['Relegation_Event_ID', 'Attendance']].rename(columns={'Attendance': 'Attendance_Y0_Baseline'})\n\n# 2. Merge this baseline back onto the main df\ndf_plot = pd.merge(df_final, df_y0_baseline, on='Relegation_Event_ID', how='left')\n\n# 3. Calculate the Pct Change vs. Year 0 for all years\ndf_plot['Pct_Change_vs_Y0'] = (\n    (df_plot['Attendance'] - df_plot['Attendance_Y0_Baseline']) / \n    df_plot['Attendance_Y0_Baseline']\n)\n\n# 4. Get the *key outcome* from Year 1 (the first post-relegation season)\ndf_y1_outcome = df_final[\n    df_final['Year_vs_Relegation'] == 1\n][['Relegation_Event_ID', 'Year_End_Outcome']].rename(columns={'Year_End_Outcome': 'Outcome_Group'})\n\n# 5. Merge this outcome group onto the whole plot dataset\ndf_plot = pd.merge(df_plot, df_y1_outcome, on='Relegation_Event_ID', how='left')\n\n\n# 5.5: IMPUTE 2024-25 OUTCOMES ---\n# The Y+1 outcome for the 2023-24 cohort is NA. We impute it manually.\nprint(\"Imputing outcomes for 2023-24 cohort...\")\n\n# Define our imputations based on likely 2024-25 season-end performance\nimpute_map = {\n    'Burnley 2023-24': 'Promoted',\n    'Sheffield United 2023-24': 'Survived', # Assuming playoffs = Survived\n    'Luton Town 2023-24': 'Relegated'\n}\n\n# Apply the imputation\n# This finds rows where Outcome_Group is NA and maps the Event ID to our new value\ndf_plot['Outcome_Group'] = df_plot['Outcome_Group'].fillna(\n    df_plot['Relegation_Event_ID'].map(impute_map)\n)\nprint(\"Imputation complete.\")\n\n# 6. Convert Pct_Change to a percentage number (e.g., 0.05 -&gt; 5)\ndf_plot['Pct_Change_vs_Y0_Display'] = df_plot['Pct_Change_vs_Y0'] * 100\n\n# 7. Calculate Per-Game metrics on the fly\ndf_plot['Goals_For_Per_Game'] = df_plot['Goals_For_History'] / df_plot['Games_Played_History']\ndf_plot['Points_Per_Game'] = df_plot['Points_History'] / df_plot['Games_Played_History']\n\n# 8. Define the FINAL anomaly list\n# We are KEEPING Wimbledon, as it's a valid case study.\nanomaly_events = [\n    'Middlesbrough 1992-93', # Rebuild\n    'Sunderland 1996-97',    # New stadium\n    'Leicester City 2001-02', # New stadium\n    'Bolton Wanderers 1995-96'  # New stadium (in Y+2)\n]\n\n# 9. Create the FINAL filtered DataFrame for plotting\ndf_plot_filtered = df_plot[~df_plot['Relegation_Event_ID'].isin(anomaly_events)]\nprint(f\"Removed {len(df_plot) - len(df_plot_filtered)} total data points for structural anomalies.\")\n\n# 10. Create the cleaner plot labels\nlabel_map = {\n    'Promoted': 'Promoted (Back in PL)',\n    'Survived': 'Survived (Still in Champ)',\n    'Relegated': 'Relegated (Down to L1)'\n}\ndf_plot['Plot_Group_Label'] = df_plot['Outcome_Group'].map(label_map)\ndf_plot_filtered['Plot_Group_Label'] = df_plot_filtered['Outcome_Group'].map(label_map)\n\nprint(\"--- Analysis data is ready. ---\")"
  }
]