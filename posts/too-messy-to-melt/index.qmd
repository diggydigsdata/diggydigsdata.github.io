
---
title: "Too Messy to Melt"
author: "Diggy"
date: "2025-11-01"
description: "Getting an analysis-ready dataset from a tabular trashcan"
image: "featured.png"
image-alt: "Image showing a sprawling and chaotic excel spreadsheet on top of a neat and tidy pandas dataframe"
categories: [Football, Analytics, Excel, Python, R, Tidy-Data]
license: "CC BY"
execute:
    echo: false
    output: false
jupyter: python3
---

#### Coming Soon

<!--
#### Tidy Data
One of the driving forces behind some of the complex logic in this dataset was that I have adapted a project I started before beginning my MSc Data Science. I had never heard of Tidy Data, so I set about chucking data into a big Excel spreadsheet. Even when I learned about Tidy Data, my Excel brain still thought it seemed like a major hassle to create a big, long table and fiddle with pd.melt or dplyr. You can just make one wide table and be done with it. But when I came back to fix up this article and add some nice plots and analytics beyond my pivot tables, I didn't quite know where to start. It was such a mess and there were so many variables that wrapping my head around them was turning into a linear algebra problem. This data wasn't just untidy, it was a statistical cesspit. Normally, it's fairly straightforward to flip a dataset from wide to long, or from dirty to tidy. Pandas has pd.melt and R has TidyR. But my data was in such a mess that neither of those would be enough. Along the way, I ended up discovering much more robust ways to engineer the variables I needed and to ensure accuracy. So a technical walkthrough to tidy this tabular trashcan is documented here.
-->